{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b02e8b6-0eaa-4989-a65a-c3ed69354199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import logging\n",
    "import warnings\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca63fc6d-eccc-40fe-b411-d3810ab2fede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7a96452-c069-44e7-b60b-5df4228af9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from GroupNormalization import GroupNormalization\n",
    "\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dccf289-82cc-4ba1-9067-5db5bd2920c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.version = 2.12.1\n",
      "tf on GPU = True\n"
     ]
    }
   ],
   "source": [
    "print('tf.version = {}'.format(tf.__version__))\n",
    "print('tf on GPU = {}'.format(tf.test.is_gpu_available()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a775ffdc-2877-4a6f-bc5e-4313baccb969",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fec1f1c1-cfd9-477f-8978-eab2f0e68f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/glade/u/home/ksha/GAN_proj/')\n",
    "sys.path.insert(0, '/glade/u/home/ksha/GAN_proj/libs/')\n",
    "\n",
    "from namelist import *\n",
    "import data_utils as du\n",
    "import model_utils as mu\n",
    "#import graph_utils as gu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08a1024-2a8f-4a29-b102-18f0ccbd9c4e",
   "metadata": {},
   "source": [
    "**Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdb55f36-d87a-4ffd-b7a7-0e447de69957",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDiffusion:\n",
    "    \"\"\"Gaussian diffusion utility.\n",
    "\n",
    "    Args:\n",
    "        beta_start: Start value of the scheduled variance\n",
    "        beta_end: End value of the scheduled variance\n",
    "        timesteps: Number of time steps in the forward process\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        beta_start=1e-4,\n",
    "        beta_end=0.02,\n",
    "        timesteps=100,\n",
    "        clip_min=-1.0,\n",
    "        clip_max=1.0,\n",
    "    ):\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.timesteps = timesteps\n",
    "        self.clip_min = clip_min\n",
    "        self.clip_max = clip_max\n",
    "\n",
    "        # Define the linear variance schedule\n",
    "        # ============ Linear ============== #\n",
    "        # self.betas = betas = np.linspace(\n",
    "        #     beta_start,\n",
    "        #     beta_end,\n",
    "        #     timesteps,\n",
    "        #     dtype=np.float64,  # Using float64 for better precision\n",
    "        # )\n",
    "        # =========== tuned =============== #\n",
    "        sch_ = (beta_end/beta_start)**(1/3)\n",
    "        self.betas = betas = np.linspace(1, sch_, timesteps, dtype=np.float64)\n",
    "        \n",
    "        self.num_timesteps = int(timesteps)\n",
    "\n",
    "        alphas = 1.0 - betas\n",
    "        alphas_cumprod = np.cumprod(alphas, axis=0)\n",
    "        alphas_cumprod_prev = np.append(1.0, alphas_cumprod[:-1])\n",
    "\n",
    "        self.betas = tf.constant(betas, dtype=tf.float32)\n",
    "        self.alphas_cumprod = tf.constant(alphas_cumprod, dtype=tf.float32)\n",
    "        self.alphas_cumprod_prev = tf.constant(alphas_cumprod_prev, dtype=tf.float32)\n",
    "\n",
    "        # Calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "        self.sqrt_alphas_cumprod = tf.constant(\n",
    "            np.sqrt(alphas_cumprod), dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        self.sqrt_one_minus_alphas_cumprod = tf.constant(\n",
    "            np.sqrt(1.0 - alphas_cumprod), dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        self.log_one_minus_alphas_cumprod = tf.constant(\n",
    "            np.log(1.0 - alphas_cumprod), dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        self.sqrt_recip_alphas_cumprod = tf.constant(\n",
    "            np.sqrt(1.0 / alphas_cumprod), dtype=tf.float32\n",
    "        )\n",
    "        self.sqrt_recipm1_alphas_cumprod = tf.constant(\n",
    "            np.sqrt(1.0 / alphas_cumprod - 1), dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        # Calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "        posterior_variance = (\n",
    "            betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod)\n",
    "        )\n",
    "        self.posterior_variance = tf.constant(posterior_variance, dtype=tf.float32)\n",
    "\n",
    "        # Log calculation clipped because the posterior variance is 0 at the beginning\n",
    "        # of the diffusion chain\n",
    "        self.posterior_log_variance_clipped = tf.constant(\n",
    "            np.log(np.maximum(posterior_variance, 1e-20)), dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        self.posterior_mean_coef1 = tf.constant(\n",
    "            betas * np.sqrt(alphas_cumprod_prev) / (1.0 - alphas_cumprod),\n",
    "            dtype=tf.float32,\n",
    "        )\n",
    "\n",
    "        self.posterior_mean_coef2 = tf.constant(\n",
    "            (1.0 - alphas_cumprod_prev) * np.sqrt(alphas) / (1.0 - alphas_cumprod),\n",
    "            dtype=tf.float32,\n",
    "        )\n",
    "\n",
    "    def _extract(self, a, t, x_shape):\n",
    "        \"\"\"Extract some coefficients at specified timesteps,\n",
    "        then reshape to [batch_size, 1, 1, 1, 1, ...] for broadcasting purposes.\n",
    "\n",
    "        Args:\n",
    "            a: Tensor to extract from\n",
    "            t: Timestep for which the coefficients are to be extracted\n",
    "            x_shape: Shape of the current batched samples\n",
    "        \"\"\"\n",
    "        batch_size = x_shape[0]\n",
    "        out = tf.gather(a, t)\n",
    "        return tf.reshape(out, [batch_size, 1, 1, 1])\n",
    "\n",
    "    def q_mean_variance(self, x_start, t):\n",
    "        \"\"\"Extracts the mean, and the variance at current timestep.\n",
    "\n",
    "        Args:\n",
    "            x_start: Initial sample (before the first diffusion step)\n",
    "            t: Current timestep\n",
    "        \"\"\"\n",
    "        x_start_shape = tf.shape(x_start)\n",
    "        mean = self._extract(self.sqrt_alphas_cumprod, t, x_start_shape) * x_start\n",
    "        variance = self._extract(1.0 - self.alphas_cumprod, t, x_start_shape)\n",
    "        log_variance = self._extract(\n",
    "            self.log_one_minus_alphas_cumprod, t, x_start_shape\n",
    "        )\n",
    "        return mean, variance, log_variance\n",
    "\n",
    "    def q_sample(self, x_start, t, noise):\n",
    "        \"\"\"Diffuse the data.\n",
    "\n",
    "        Args:\n",
    "            x_start: Initial sample (before the first diffusion step)\n",
    "            t: Current timestep\n",
    "            noise: Gaussian noise to be added at the current timestep\n",
    "        Returns:\n",
    "            Diffused samples at timestep `t`\n",
    "        \"\"\"\n",
    "        x_start_shape = tf.shape(x_start)\n",
    "        return (\n",
    "            self._extract(self.sqrt_alphas_cumprod, t, tf.shape(x_start)) * x_start\n",
    "            + self._extract(self.sqrt_one_minus_alphas_cumprod, t, x_start_shape)\n",
    "            * noise\n",
    "        )\n",
    "\n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        x_t_shape = tf.shape(x_t)\n",
    "        return (\n",
    "            self._extract(self.sqrt_recip_alphas_cumprod, t, x_t_shape) * x_t\n",
    "            - self._extract(self.sqrt_recipm1_alphas_cumprod, t, x_t_shape) * noise\n",
    "        )\n",
    "\n",
    "    def q_posterior(self, x_start, x_t, t):\n",
    "        \"\"\"Compute the mean and variance of the diffusion\n",
    "        posterior q(x_{t-1} | x_t, x_0).\n",
    "\n",
    "        Args:\n",
    "            x_start: Stating point(sample) for the posterior computation\n",
    "            x_t: Sample at timestep `t`\n",
    "            t: Current timestep\n",
    "        Returns:\n",
    "            Posterior mean and variance at current timestep\n",
    "        \"\"\"\n",
    "\n",
    "        x_t_shape = tf.shape(x_t)\n",
    "        posterior_mean = (\n",
    "            self._extract(self.posterior_mean_coef1, t, x_t_shape) * x_start\n",
    "            + self._extract(self.posterior_mean_coef2, t, x_t_shape) * x_t\n",
    "        )\n",
    "        posterior_variance = self._extract(self.posterior_variance, t, x_t_shape)\n",
    "        posterior_log_variance_clipped = self._extract(\n",
    "            self.posterior_log_variance_clipped, t, x_t_shape\n",
    "        )\n",
    "        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
    "\n",
    "    def p_mean_variance(self, pred_noise, x, t, clip_denoised=True):\n",
    "        x_recon = self.predict_start_from_noise(x, t=t, noise=pred_noise)\n",
    "        if clip_denoised:\n",
    "            x_recon = tf.clip_by_value(x_recon, self.clip_min, self.clip_max)\n",
    "\n",
    "        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(\n",
    "            x_start=x_recon, x_t=x, t=t\n",
    "        )\n",
    "        return model_mean, posterior_variance, posterior_log_variance\n",
    "\n",
    "    def p_sample(self, pred_noise, x, t, clip_denoised=True):\n",
    "        \"\"\"Sample from the diffusion model.\n",
    "\n",
    "        Args:\n",
    "            pred_noise: Noise predicted by the diffusion model\n",
    "            x: Samples at a given timestep for which the noise was predicted\n",
    "            t: Current timestep\n",
    "            clip_denoised (bool): Whether to clip the predicted noise\n",
    "                within the specified range or not.\n",
    "        \"\"\"\n",
    "        model_mean, _, model_log_variance = self.p_mean_variance(\n",
    "            pred_noise, x=x, t=t, clip_denoised=clip_denoised\n",
    "        )\n",
    "        noise = tf.random.normal(shape=x.shape, dtype=x.dtype)\n",
    "        # No noise when t == 0\n",
    "        nonzero_mask = tf.reshape(\n",
    "            1 - tf.cast(tf.equal(t, 0), tf.float32), [tf.shape(x)[0], 1, 1, 1]\n",
    "        )\n",
    "        return model_mean + nonzero_mask * tf.exp(0.5 * model_log_variance) * noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a9b23d-4d42-40d6-881c-efc9e68838f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c92957e-dd73-45bb-8fe2-8e03d40691ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel initializer to use\n",
    "def kernel_init(scale):\n",
    "    scale = max(scale, 1e-10)\n",
    "    return keras.initializers.VarianceScaling(\n",
    "        scale, mode=\"fan_avg\", distribution=\"uniform\"\n",
    "    )\n",
    "\n",
    "class TimeEmbedding(layers.Layer):\n",
    "    def __init__(self, dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.half_dim = dim // 2\n",
    "        self.emb = math.log(10000) / (self.half_dim - 1)\n",
    "        self.emb = tf.exp(tf.range(self.half_dim, dtype=tf.float32) * -self.emb)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = tf.cast(inputs, dtype=tf.float32)\n",
    "        emb = inputs[:, None] * self.emb[None, :]\n",
    "        emb = tf.concat([tf.sin(emb), tf.cos(emb)], axis=-1)\n",
    "        return emb\n",
    "\n",
    "\n",
    "def ResidualBlock(width, groups=8, activation_fn=keras.activations.swish):\n",
    "    def apply(inputs):\n",
    "        x, t = inputs\n",
    "        input_width = x.shape[3]\n",
    "\n",
    "        if input_width == width:\n",
    "            residual = x\n",
    "        else:\n",
    "            residual = layers.Conv2D(\n",
    "                width, kernel_size=1, kernel_initializer=kernel_init(1.0)\n",
    "            )(x)\n",
    "\n",
    "        temb = activation_fn(t)\n",
    "        temb = layers.Dense(width, kernel_initializer=kernel_init(1.0))(temb)[\n",
    "            :, None, None, :\n",
    "        ]\n",
    "\n",
    "        x = layers.GroupNormalization(groups=groups)(x)\n",
    "        x = activation_fn(x)\n",
    "        x = layers.Conv2D(\n",
    "            width, kernel_size=3, padding=\"same\", kernel_initializer=kernel_init(1.0)\n",
    "        )(x)\n",
    "\n",
    "        x = layers.Add()([x, temb])\n",
    "        x = layers.GroupNormalization(groups=groups)(x)\n",
    "        x = activation_fn(x)\n",
    "\n",
    "        x = layers.Conv2D(\n",
    "            width, kernel_size=3, padding=\"same\", kernel_initializer=kernel_init(0.0)\n",
    "        )(x)\n",
    "        x = layers.Add()([x, residual])\n",
    "        return x\n",
    "\n",
    "    return apply\n",
    "\n",
    "\n",
    "def DownSample(width):\n",
    "    def apply(x):\n",
    "        x = layers.Conv2D(\n",
    "            width,\n",
    "            kernel_size=3,\n",
    "            strides=2,\n",
    "            padding=\"same\",\n",
    "            kernel_initializer=kernel_init(1.0),\n",
    "        )(x)\n",
    "        return x\n",
    "\n",
    "    return apply\n",
    "\n",
    "\n",
    "def UpSample(width, interpolation=\"nearest\"):\n",
    "    def apply(x):\n",
    "        x = layers.UpSampling2D(size=2, interpolation=interpolation)(x)\n",
    "        x = layers.Conv2D(\n",
    "            width, kernel_size=3, padding=\"same\", kernel_initializer=kernel_init(1.0)\n",
    "        )(x)\n",
    "        return x\n",
    "\n",
    "    return apply\n",
    "\n",
    "\n",
    "def TimeMLP(units, activation_fn=keras.activations.swish):\n",
    "    def apply(inputs):\n",
    "        temb = layers.Dense(\n",
    "            units, activation=activation_fn, kernel_initializer=kernel_init(1.0)\n",
    "        )(inputs)\n",
    "        temb = layers.Dense(units, kernel_initializer=kernel_init(1.0))(temb)\n",
    "        return temb\n",
    "\n",
    "    return apply\n",
    "\n",
    "\n",
    "# def build_model(input_shape, gfs_shape, widths, has_attention, num_res_blocks=2, norm_groups=8,\n",
    "#                 interpolation=\"nearest\", activation_fn=keras.activations.swish,):\n",
    "    \n",
    "#     image_input = layers.Input(shape=input_shape, name=\"image_input\")\n",
    "#     time_input = keras.Input(shape=(), dtype=tf.int64, name=\"time_input\")\n",
    "#     gfs_input = layers.Input(shape=gfs_shape, name=\"gfs_input\")\n",
    "    \n",
    "#     x = layers.Conv2D(first_conv_channels, kernel_size=(3, 3), padding=\"same\",\n",
    "#                       kernel_initializer=kernel_init(1.0),)(image_input)\n",
    "\n",
    "#     temb = TimeEmbedding(dim=first_conv_channels * 4)(time_input)\n",
    "#     temb = TimeMLP(units=first_conv_channels * 4, activation_fn=activation_fn)(temb)\n",
    "\n",
    "#     skips = [x]\n",
    "\n",
    "#     # DownBlock\n",
    "#     for i in range(len(widths)):\n",
    "#         for _ in range(num_res_blocks):\n",
    "#             x = ResidualBlock(widths[i], groups=norm_groups, activation_fn=activation_fn)([x, temb])\n",
    "            \n",
    "#             if has_attention[i]:\n",
    "#                 x_gfs = layers.Conv2D(widths[i], kernel_size=(2**i, 2**i), strides=2**i, padding=\"same\",)(gfs_input)\n",
    "#                 x = layers.MultiHeadAttention(num_heads=norm_groups, key_dim=widths[i])(x, x_gfs)\n",
    "                \n",
    "#             skips.append(x)\n",
    "\n",
    "#         if widths[i] != widths[-1]:\n",
    "#             x = DownSample(widths[i])(x)\n",
    "#             skips.append(x)\n",
    "\n",
    "#     # MiddleBlock\n",
    "#     x = ResidualBlock(widths[-1], groups=norm_groups, activation_fn=activation_fn)([x, temb])\n",
    "    \n",
    "#     x_gfs = layers.Conv2D(widths[-1], kernel_size=(8, 8), strides=8, padding=\"same\",)(gfs_input)\n",
    "#     x = layers.MultiHeadAttention(num_heads=norm_groups, key_dim=widths[-1])(x, x_gfs)\n",
    "    \n",
    "#     x = ResidualBlock(widths[-1], groups=norm_groups, activation_fn=activation_fn)([x, temb])\n",
    "\n",
    "#     # UpBlock\n",
    "#     for i in reversed(range(len(widths))):\n",
    "#         for _ in range(num_res_blocks + 1):\n",
    "#             x = layers.Concatenate(axis=-1)([x, skips.pop()])\n",
    "#             x = ResidualBlock(widths[i], groups=norm_groups, activation_fn=activation_fn)([x, temb])\n",
    "            \n",
    "#             if has_attention[i]:\n",
    "#                 x_gfs = layers.Conv2D(widths[i], kernel_size=(2**i, 2**i), strides=2**i, padding=\"same\",)(gfs_input)\n",
    "#                 x = layers.MultiHeadAttention(num_heads=norm_groups, key_dim=widths[i])(x, x_gfs)\n",
    "\n",
    "#         if i != 0:\n",
    "#             x = UpSample(widths[i], interpolation=interpolation)(x)\n",
    "\n",
    "#     # End block\n",
    "#     x = layers.GroupNormalization(groups=norm_groups)(x)\n",
    "#     x = activation_fn(x)\n",
    "#     x = layers.Conv2D(1, (3, 3), padding=\"same\", kernel_initializer=kernel_init(0.0))(x)\n",
    "#     return keras.Model([image_input, time_input, gfs_input], x, name=\"unet\")\n",
    "\n",
    "def build_model(input_shape, gfs_shape, widths, has_attention, num_res_blocks=2, norm_groups=8,\n",
    "                interpolation=\"nearest\", activation_fn=keras.activations.swish,):\n",
    "    \n",
    "    image_input = layers.Input(shape=input_shape, name=\"image_input\")\n",
    "    time_input = keras.Input(shape=(), dtype=tf.int64, name=\"time_input\")\n",
    "    gfs_input = layers.Input(shape=gfs_shape, name=\"gfs_input\")\n",
    "    \n",
    "    x = layers.Conv2D(first_conv_channels, kernel_size=(3, 3), padding=\"same\",\n",
    "                      kernel_initializer=kernel_init(1.0),)(image_input)\n",
    "\n",
    "    temb = TimeEmbedding(dim=first_conv_channels * 4)(time_input)\n",
    "    temb = TimeMLP(units=first_conv_channels * 4, activation_fn=activation_fn)(temb)\n",
    "\n",
    "    skips = [x]\n",
    "\n",
    "    # DownBlock\n",
    "    for i in range(len(widths)):\n",
    "        for _ in range(num_res_blocks):\n",
    "            x = ResidualBlock(widths[i], groups=norm_groups, activation_fn=activation_fn)([x, temb])\n",
    "            \n",
    "            if has_attention[i]:\n",
    "                x_gfs = gfs_input\n",
    "                for _ in range(i):\n",
    "                    x_gfs = layers.Conv2D(widths[i], kernel_size=(2, 2), strides=2, padding=\"same\",)(x_gfs)\n",
    "                x = layers.MultiHeadAttention(num_heads=norm_groups, key_dim=widths[i])(x, x_gfs)\n",
    "                \n",
    "            skips.append(x)\n",
    "\n",
    "        if widths[i] != widths[-1]:\n",
    "            x = DownSample(widths[i])(x)\n",
    "            skips.append(x)\n",
    "\n",
    "    # MiddleBlock\n",
    "    x = ResidualBlock(widths[-1], groups=norm_groups, activation_fn=activation_fn)([x, temb])\n",
    "    \n",
    "    x_gfs = gfs_input\n",
    "    for _ in range(3):\n",
    "        x_gfs = layers.Conv2D(widths[i], kernel_size=(2, 2), strides=2, padding=\"same\",)(x_gfs)\n",
    "    x = layers.MultiHeadAttention(num_heads=norm_groups, key_dim=widths[i])(x, x_gfs)\n",
    "    x = layers.MultiHeadAttention(num_heads=norm_groups, key_dim=widths[-1])(x, x_gfs)\n",
    "    \n",
    "    x = ResidualBlock(widths[-1], groups=norm_groups, activation_fn=activation_fn)([x, temb])\n",
    "\n",
    "    # UpBlock\n",
    "    for i in reversed(range(len(widths))):\n",
    "        for _ in range(num_res_blocks + 1):\n",
    "            x = layers.Concatenate(axis=-1)([x, skips.pop()])\n",
    "            x = ResidualBlock(widths[i], groups=norm_groups, activation_fn=activation_fn)([x, temb])\n",
    "            \n",
    "            if has_attention[i]:\n",
    "                x_gfs = gfs_input\n",
    "                for _ in range(i):\n",
    "                    x_gfs = layers.Conv2D(widths[i], kernel_size=(2, 2), strides=2, padding=\"same\",)(x_gfs)\n",
    "                x = layers.MultiHeadAttention(num_heads=norm_groups, key_dim=widths[i])(x, x_gfs)\n",
    "\n",
    "        if i != 0:\n",
    "            x = UpSample(widths[i], interpolation=interpolation)(x)\n",
    "\n",
    "    # End block\n",
    "    x = layers.GroupNormalization(groups=norm_groups)(x)\n",
    "    x = activation_fn(x)\n",
    "    x = layers.Conv2D(input_shape[-1], (3, 3), padding=\"same\", kernel_initializer=kernel_init(0.0))(x)\n",
    "    return keras.Model([image_input, time_input, gfs_input], x, name=\"unet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad250c4-f0c7-433b-b2e0-b66172ce092e",
   "metadata": {},
   "source": [
    "# config model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ab3d4c6-80c1-42df-a6aa-eed53a1d0954",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_timesteps = 100\n",
    "norm_groups = 8  # Number of groups used in GroupNormalization layer\n",
    "lr = 1e-4\n",
    "\n",
    "clip_min = -1.0\n",
    "clip_max = 1.0\n",
    "\n",
    "\n",
    "widths = [64, 96, 128, 256]\n",
    "first_conv_channels = widths[0]\n",
    "\n",
    "has_attention = [False, False, False, True]\n",
    "num_res_blocks = 1  # Number of residual blocks\n",
    "\n",
    "model_name = '/glade/work/ksha/GAN/models/LDM_base/'\n",
    "\n",
    "\n",
    "input_shape = (32, 32, 16)\n",
    "gfs_shape = (32, 32, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "807696f7-bfc6-497e-9f61-4b58a7a2a12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the unet model\n",
    "model = build_model(input_shape=input_shape, gfs_shape=gfs_shape, widths=widths,\n",
    "                    has_attention=has_attention, num_res_blocks=num_res_blocks, \n",
    "                    norm_groups=norm_groups, activation_fn=keras.activations.swish)\n",
    "\n",
    "#17,565,729\n",
    "#17,602,017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2230b22-1530-434a-b4c3-d4611d6b0dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss=keras.losses.MeanAbsoluteError(), optimizer=keras.optimizers.Adam(learning_rate=1e-4),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29083cdc-e644-4996-b90b-393017658dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# W_old = mu.dummy_loader(model_name)\n",
    "# model.set_weights(W_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e55111d0-ca80-4924-8aac-43b3c0d86c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_util = GaussianDiffusion(timesteps=total_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4317431d-bed0-4e44-a513-e1ec61779775",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_dir = '/glade/campaign/cisl/aiml/ksha/BATCH_LDM/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a1854e9-110b-4353-b307-392c7a4f8792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_diffuse(model, x_in1, x_in2, total_timesteps, gdf_util):\n",
    "    L_valid = len(x_in1)\n",
    "    x_out = np.empty(x_in1.shape)\n",
    "\n",
    "    for i in range(L_valid):\n",
    "        x1 = x_in1[i, ...][None, ...]\n",
    "        x2 = x_in2[i, ...][None, ...]\n",
    "        \n",
    "        for t in reversed(range(0, total_timesteps)):\n",
    "            tt = tf.cast(tf.fill(1, t), dtype=tf.int64)\n",
    "            pred_noise = model.predict([x1, tt, x2], verbose=0)\n",
    "            model_mean, _, model_log_variance =  gdf_util.p_mean_variance(pred_noise, x=x1, t=tt, clip_denoised=True)\n",
    "            nonzero_mask = (1 - (np.array(tt)==0)).reshape((1, 1, 1, 1))\n",
    "            x1 = np.array(model_mean) + nonzero_mask * np.exp(0.5 * np.array(model_log_variance)) * np.random.normal(size=x1.shape)\n",
    "        x_out[i, ...] = x1\n",
    "\n",
    "    return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa3786d2-836a-4de0-a3fc-9923f23eee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "640328a9-0809-45cd-9741-3a745ce1c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "F_x = 0.1\n",
    "F_y = 1/2.76\n",
    "\n",
    "L_valid = 32\n",
    "\n",
    "filenames = np.array(sorted(glob(BATCH_dir+'*.npy')))\n",
    "\n",
    "L = len(filenames)\n",
    "filename_valid = filenames[:][:L_valid]\n",
    "filename_train = list(set(filenames) - set(filename_valid))\n",
    "\n",
    "L_train = len(filename_train)\n",
    "\n",
    "Y_valid = np.empty((L_valid, 32, 32, 16))\n",
    "X_valid = np.empty((L_valid, 32, 32, 256))\n",
    "\n",
    "for i, name in enumerate(filename_valid):\n",
    "    temp_data = np.load(name, allow_pickle=True)[()]\n",
    "    X_valid[i, ...] = F_x*temp_data['GFS_latent']\n",
    "    Y_valid[i, ...] = F_y*temp_data['Y_latent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40985ec0-39c7-4f07-97ea-4cbcd8ab0249",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_valid_ = np.random.uniform(low=0, high=total_timesteps, size=(L_valid,)) #(total_timesteps-1)*np.ones(L_valid) #\n",
    "t_valid = t_valid_.astype(int)\n",
    "\n",
    "# sample random noise to be added to the images in the batch\n",
    "noise_valid = np.random.normal(size=(L_valid, 32, 32, 16))\n",
    "images_valid = np.array(gdf_util.q_sample(Y_valid, t_valid, noise_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11556643-9a41-40d9-99aa-0d3e9458a93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "# Y_pred = reverse_diffuse(model, images_valid, X_valid, total_timesteps, gdf_util)\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bb9fc58-d420-4e01-a201-4d28551bce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_in1 = images_valid\n",
    "# x_in2 = X_valid\n",
    "\n",
    "# x1 = x_in1[i, ...][None, ...]\n",
    "# x2 = x_in2[i, ...][None, ...]\n",
    "        \n",
    "# for t in reversed(range(0, total_timesteps)):\n",
    "#     tt = tf.cast(tf.fill(1, t), dtype=tf.int64)\n",
    "#     pred_noise = model.predict([x1, tt, x2], verbose=0)\n",
    "#     model_mean, _, model_log_variance =  gdf_util.p_mean_variance(pred_noise, x=x1, t=tt, clip_denoised=True)\n",
    "#     nonzero_mask = (1 - (np.array(tt)==0)).reshape((1, 1, 1, 1))\n",
    "#     x1 = np.array(model_mean) + nonzero_mask * np.exp(0.5 * np.array(model_log_variance)) * np.random.normal(size=x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7935aca4-0ecf-4fc7-b55a-cc936b87d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_noise = model.predict([images_valid, t_valid, X_valid])\n",
    "# record = np.mean(np.abs(noise_valid - pred_noise))\n",
    "# print('initial loss {}'.format(record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483f8682-f748-4c45-9765-134c2a9462ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "Initial validation loss: 0.797513172304641\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "Validation loss improved from 0.797513172304641 to 0.5559610733509978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 471.420521736145 seconds ---\n",
      "epoch = 1\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "Validation loss improved from 0.5559610733509978 to 0.3403905973686788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 402.20895886421204 seconds ---\n",
      "epoch = 2\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "Validation loss improved from 0.3403905973686788 to 0.22919090064767977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 389.10267972946167 seconds ---\n",
      "epoch = 3\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "Validation loss improved from 0.22919090064767977 to 0.2027314528156189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 389.27508449554443 seconds ---\n",
      "epoch = 4\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "Validation loss improved from 0.2027314528156189 to 0.18128846542139904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 398.464955329895 seconds ---\n",
      "epoch = 5\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "Validation loss improved from 0.18128846542139904 to 0.16057621433272762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 461.9826326370239 seconds ---\n",
      "epoch = 6\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "Validation loss improved from 0.16057621433272762 to 0.14289869076055428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 533.4157667160034 seconds ---\n",
      "epoch = 7\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "Validation loss improved from 0.14289869076055428 to 0.1284261688872051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 527.249320268631 seconds ---\n",
      "epoch = 8\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "Validation loss improved from 0.1284261688872051 to 0.11621552889745633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 538.7512350082397 seconds ---\n",
      "epoch = 9\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "Validation loss improved from 0.11621552889745633 to 0.1059909117553423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 408.60932087898254 seconds ---\n",
      "epoch = 10\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "Validation loss improved from 0.1059909117553423 to 0.09716345015866287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 404.4019560813904 seconds ---\n",
      "epoch = 11\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "Validation loss improved from 0.09716345015866287 to 0.0896161981162007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 416.0437467098236 seconds ---\n",
      "epoch = 12\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "Validation loss improved from 0.0896161981162007 to 0.08273929819448905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 416.95712447166443 seconds ---\n",
      "epoch = 13\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "Validation loss improved from 0.08273929819448905 to 0.07722468002175827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 438.0843915939331 seconds ---\n",
      "epoch = 14\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "Validation loss improved from 0.07722468002175827 to 0.07227678327661065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 484.0047941207886 seconds ---\n",
      "epoch = 15\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "Validation loss improved from 0.07227678327661065 to 0.06798663757803595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 417.7964925765991 seconds ---\n",
      "epoch = 16\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "Validation loss improved from 0.06798663757803595 to 0.06409516549404144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 405.55396795272827 seconds ---\n",
      "epoch = 17\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "Validation loss improved from 0.06409516549404144 to 0.060697814228430895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 387.5766806602478 seconds ---\n",
      "epoch = 18\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "Validation loss improved from 0.060697814228430895 to 0.05797634668941367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 404.45651412010193 seconds ---\n",
      "epoch = 19\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "Validation loss improved from 0.05797634668941367 to 0.05545675097770402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 455.4145929813385 seconds ---\n",
      "epoch = 20\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "Validation loss improved from 0.05545675097770402 to 0.052888227889087716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 424.20606565475464 seconds ---\n",
      "epoch = 21\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "Validation loss improved from 0.052888227889087716 to 0.05097449092689509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 458.1558723449707 seconds ---\n",
      "epoch = 22\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "Validation loss improved from 0.05097449092689509 to 0.048967857496122404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 415.1968629360199 seconds ---\n",
      "epoch = 23\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "Validation loss improved from 0.048967857496122404 to 0.04747930620211306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 550.704274892807 seconds ---\n",
      "epoch = 24\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "Validation loss improved from 0.04747930620211306 to 0.04543046127853685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 613.0236401557922 seconds ---\n",
      "epoch = 25\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "Validation loss improved from 0.04543046127853685 to 0.04400997001089581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 526.2651669979095 seconds ---\n",
      "epoch = 26\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "Validation loss improved from 0.04400997001089581 to 0.043091280638278974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 474.00400161743164 seconds ---\n",
      "epoch = 27\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "Validation loss improved from 0.043091280638278974 to 0.04134070614884069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 445.8767900466919 seconds ---\n",
      "epoch = 28\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "Validation loss improved from 0.04134070614884069 to 0.040291605338835426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 420.67860651016235 seconds ---\n",
      "epoch = 29\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "Validation loss improved from 0.040291605338835426 to 0.03936077880618272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 517.3442347049713 seconds ---\n",
      "epoch = 30\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "Validation loss improved from 0.03936077880618272 to 0.03887766951133284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 588.3358027935028 seconds ---\n",
      "epoch = 31\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "Validation loss improved from 0.03887766951133284 to 0.03724375688500586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 543.2640764713287 seconds ---\n",
      "epoch = 32\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "Validation loss improved from 0.03724375688500586 to 0.036526212945955996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 508.91004371643066 seconds ---\n",
      "epoch = 33\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "Validation loss improved from 0.036526212945955996 to 0.03549530360254592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 484.5173268318176 seconds ---\n",
      "epoch = 34\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "Validation loss improved from 0.03549530360254592 to 0.03465105223460907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 612.5016539096832 seconds ---\n",
      "epoch = 35\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "Validation loss improved from 0.03465105223460907 to 0.033886106169804406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 534.8786282539368 seconds ---\n",
      "epoch = 36\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "Validation loss improved from 0.033886106169804406 to 0.03326138906762922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 618.2382049560547 seconds ---\n",
      "epoch = 37\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "Validation loss improved from 0.03326138906762922 to 0.032582565489026015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 553.2573931217194 seconds ---\n",
      "epoch = 38\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "Validation loss improved from 0.032582565489026015 to 0.031982645766156184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 617.039960861206 seconds ---\n",
      "epoch = 39\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "Validation loss improved from 0.031982645766156184 to 0.03186714786632341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 520.8185844421387 seconds ---\n",
      "epoch = 40\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "Validation loss improved from 0.03186714786632341 to 0.0309703045973853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 403.2380769252777 seconds ---\n",
      "epoch = 41\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "Validation loss 0.031139389200003646 NOT improved\n",
      "--- 387.69413447380066 seconds ---\n",
      "epoch = 42\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "Validation loss improved from 0.0309703045973853 to 0.030427886833236353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 451.3786346912384 seconds ---\n",
      "epoch = 43\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "Validation loss improved from 0.030427886833236353 to 0.02991023203615282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 428.2513630390167 seconds ---\n",
      "epoch = 44\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "Validation loss improved from 0.02991023203615282 to 0.029149318553441404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 413.3736572265625 seconds ---\n",
      "epoch = 45\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "Validation loss improved from 0.029149318553441404 to 0.02909479913815121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 405.3245346546173 seconds ---\n",
      "epoch = 46\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "Validation loss improved from 0.02909479913815121 to 0.028391452501605147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 407.5135726928711 seconds ---\n",
      "epoch = 47\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "Validation loss improved from 0.028391452501605147 to 0.028006451677511913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 425.7228271961212 seconds ---\n",
      "epoch = 48\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "Validation loss improved from 0.028006451677511913 to 0.027501218645962083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 390.87215781211853 seconds ---\n",
      "epoch = 49\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "Validation loss improved from 0.027501218645962083 to 0.02719560320606552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 386.37936782836914 seconds ---\n",
      "epoch = 50\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "Validation loss improved from 0.02719560320606552 to 0.026697202905771315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 120). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 408.9744567871094 seconds ---\n",
      "epoch = 51\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "Validation loss 0.02693225497113441 NOT improved\n",
      "--- 361.71693873405457 seconds ---\n",
      "epoch = 52\n"
     ]
    }
   ],
   "source": [
    "# ====================== #\n",
    "filenames = np.array(sorted(glob(BATCH_dir+'*.npy')))\n",
    "L = len(filenames)\n",
    "filename_valid = filenames[:L_valid]\n",
    "filename_train = list(set(filenames) - set(filename_valid))\n",
    "L_train = len(filename_train)\n",
    "# ====================== #\n",
    "\n",
    "epochs = 99999\n",
    "N_batch = 128\n",
    "batch_size = 64 #32\n",
    "\n",
    "min_del = 0.0\n",
    "max_tol = 3 # early stopping with 2-epoch patience\n",
    "tol = 0\n",
    "\n",
    "Y_batch = np.empty((batch_size, 32, 32, 16))\n",
    "X_batch = np.empty((batch_size, 32, 32, 256))\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    print('epoch = {}'.format(i))\n",
    "    if i == 0:\n",
    "        pred_noise = model.predict([images_valid, t_valid, X_valid])\n",
    "        record = np.mean(np.abs(noise_valid - pred_noise))\n",
    "        #print('initial loss {}'.format(record))\n",
    "        print('Initial validation loss: {}'.format(record))\n",
    "        \n",
    "    start_time = time.time()\n",
    "    # loop over batches\n",
    "    \n",
    "    for j in range(N_batch):\n",
    "\n",
    "        # collect training batches\n",
    "        \n",
    "        inds_rnd = du.shuffle_ind(L_train)\n",
    "        inds_ = inds_rnd[:batch_size]\n",
    "\n",
    "        for k, ind in enumerate(inds_):\n",
    "            # import batch data\n",
    "            temp_name = filename_train[ind]\n",
    "            temp_data = np.load(temp_name, allow_pickle=True)[()]\n",
    "            X_batch[k, ...] = F_x*temp_data['GFS_latent']\n",
    "            Y_batch[k, ...] = F_y*temp_data['Y_latent']\n",
    "\n",
    "        # sample timesteps uniformly\n",
    "        t_ = np.random.uniform(low=0, high=total_timesteps, size=(batch_size,))\n",
    "        t = t_.astype(int)\n",
    "\n",
    "        # sample random noise to be added to the images in the batch\n",
    "        noise = np.random.normal(size=(batch_size, 32, 32, 16))\n",
    "        images_t = np.array(gdf_util.q_sample(Y_batch, t, noise))\n",
    "\n",
    "        model.train_on_batch([images_t, t, X_batch], noise)\n",
    "        \n",
    "    # on epoch-end\n",
    "    # Y_pred = reverse_diffuse(model, images_valid, X_valid, total_timesteps, gdf_util)\n",
    "    # record_temp = mean_absolute_error(Y_valid, Y_pred)\n",
    "    pred_noise = model.predict([images_valid, t_valid, X_valid])\n",
    "    record_temp = np.mean(np.abs(noise_valid - pred_noise))\n",
    "    \n",
    "    # print out valid loss change\n",
    "    if record - record_temp > min_del:\n",
    "        print('Validation loss improved from {} to {}'.format(record, record_temp))\n",
    "        record = record_temp\n",
    "        model.save(model_name)\n",
    "        \n",
    "    else:\n",
    "        print('Validation loss {} NOT improved'.format(record_temp))\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    # mannual callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8079dbea-f1ee-4e8f-b261-5d0170544e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 190ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_noise = model.predict([images_valid, t_valid, X_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a33514b-c514-4add-bd30-e7ba8807efdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 32, 16)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108d00b7-4fad-488e-9008-df267affe57a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e99068-6614-4234-8da0-aa52e36a9f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d5e972-1245-48de-908d-77582c5c471e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925440e9-00c9-42fa-b055-cad39befe902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c344af8-09a7-4e8c-8002-b6907e979925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12c4239-4a8d-4282-904d-a970258b6e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4060ca4c-80c1-480e-ae2c-4229b09d5a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Sample timesteps uniformly\n",
    "t_ = np.random.uniform(low=0, high=total_timesteps, size=(batch_size,))\n",
    "t = t_.astype(int)\n",
    "\n",
    "# 3. Sample random noise to be added to the images in the batch\n",
    "noise = np.random.normal(size=(batch_size, 128, 128, 1))\n",
    "\n",
    "images_t_ = np.array(gdf_util.q_sample(Y_valid_HR, t, noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f61e9be-815b-46dc-8eba-808b29352648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb0b735-e86d-465d-9773-843e039775a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7a9525-cb77-414c-b67c-e7abb38bcaa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869b3b1e-9fba-4b98-ae3e-f970bbb7193d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce1592c-8cce-4f93-90db-ed28555065f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
