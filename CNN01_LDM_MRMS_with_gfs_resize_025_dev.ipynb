{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7184eacc-7e1f-4419-b3c2-028a9009eff5",
   "metadata": {},
   "source": [
    "# Latent diffusion model without GFS embeddings\n",
    "\n",
    "* The cross-attention version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7a96452-c069-44e7-b60b-5df4228af9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import logging\n",
    "import warnings\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# supress regular warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR) \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# supress tensorflow warnings\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# adjust for time step embedding layer\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3672c482-0d89-4cac-b730-1003d2f3b94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dccf289-82cc-4ba1-9067-5db5bd2920c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/glade/u/home/ksha/GAN_proj/')\n",
    "sys.path.insert(0, '/glade/u/home/ksha/GAN_proj/libs/')\n",
    "\n",
    "from namelist import *\n",
    "import data_utils as du\n",
    "import model_utils as mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08a1024-2a8f-4a29-b102-18f0ccbd9c4e",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdb55f36-d87a-4ffd-b7a7-0e447de69957",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_timesteps = 50 # diffusion time steps\n",
    "norm_groups = 8 # number of attention heads, number of layer normalization groups \n",
    "\n",
    "# min-max values of the diffusion target (learning target) \n",
    "clip_min = -1.0\n",
    "clip_max = 1.0\n",
    "\n",
    "precip_max = np.log(100+1)\n",
    "\n",
    "input_shape = (128, 256, 1) # the tensor shape of reverse diffusion input\n",
    "gfs_shape = (128, 256, 8) # the tensor shape of GFS embeddings\n",
    "\n",
    "widths = [64, 96, 128, 256] # number of convolution kernels per up-/downsampling level\n",
    "feature_sizes = [32, 16, 8, 4]\n",
    "\n",
    "left_attention = [False, False, True, True] # True: use multi-head attnetion on each up-/downsampling level\n",
    "right_attention = [False, False, True, True]\n",
    "num_res_blocks = 2  # Number of residual blocks\n",
    "\n",
    "N_atten1 = np.sum(left_attention)\n",
    "N_atten2 = np.sum(right_attention)\n",
    "\n",
    "load_weights = True # True: load previous weights\n",
    "# location of the previous weights\n",
    "model_name = '/glade/work/ksha/GAN/models/LDM_025_resize{}-{}_res{}_tune1/'.format(\n",
    "    N_atten1, N_atten2, num_res_blocks)\n",
    "\n",
    "# location for saving new weights\n",
    "model_name_save = '/glade/work/ksha/GAN/models/LDM_025_resize{}-{}_res{}_tune2/'.format(\n",
    "    N_atten1, N_atten2, num_res_blocks)\n",
    "\n",
    "lr = 1e-5 # learning rate\n",
    "\n",
    "# samples per epoch = N_batch * batch_size\n",
    "epochs = 99999\n",
    "N_batch = 128\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117e5f1c-85e9-41b5-b868-519e18b36da3",
   "metadata": {},
   "source": [
    "## Model design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3d57ca9-78f0-4eab-a106-83a4a7773565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, gfs_shape, widths, feature_sizes, left_attention, right_attention, num_res_blocks=2, norm_groups=8,\n",
    "                interpolation='bilinear', activation_fn=keras.activations.swish,):\n",
    "\n",
    "    first_conv_channels = widths[0]\n",
    "    \n",
    "    image_input = layers.Input(shape=input_shape, name=\"image_input\")\n",
    "    time_input = keras.Input(shape=(), dtype=tf.int64, name=\"time_input\")\n",
    "    gfs_input = layers.Input(shape=gfs_shape, name=\"gfs_input\")\n",
    "    \n",
    "    x = layers.Conv2D(first_conv_channels, kernel_size=(3, 3), padding=\"same\",\n",
    "                      kernel_initializer=mu.kernel_init(1.0),)(image_input)\n",
    "\n",
    "    temb = mu.TimeEmbedding(dim=first_conv_channels * 4)(time_input)\n",
    "    temb = mu.TimeMLP(units=first_conv_channels * 4, activation_fn=activation_fn)(temb)\n",
    "\n",
    "    skips = [x]\n",
    "\n",
    "    # DownBlock\n",
    "    has_attention = left_attention\n",
    "    for i in range(len(widths)):\n",
    "        for _ in range(num_res_blocks):\n",
    "            x = mu.ResidualBlock(widths[i], groups=norm_groups, activation_fn=activation_fn)([x, temb])\n",
    "            \n",
    "            if has_attention[i]:\n",
    "                # GFS cross-attention inputs\n",
    "                size_ = feature_sizes[i]\n",
    "                x_gfs = gfs_input\n",
    "                x_gfs = layers.Resizing(size_, 2*size_, interpolation='bilinear')(x_gfs)\n",
    "\n",
    "                x_gfs = layers.Conv2D(int(0.5*widths[i]), kernel_size=(3, 3), padding=\"same\",)(x_gfs)\n",
    "                x_gfs = layers.GroupNormalization(groups=norm_groups)(x_gfs)\n",
    "                x_gfs = activation_fn(x_gfs)\n",
    "\n",
    "                x_gfs = layers.Conv2D(widths[i], kernel_size=(3, 3), padding=\"same\",)(x_gfs)\n",
    "                x_gfs = layers.GroupNormalization(groups=norm_groups)(x_gfs)\n",
    "                x_gfs = activation_fn(x_gfs)\n",
    "                \n",
    "                x = layers.MultiHeadAttention(num_heads=norm_groups, key_dim=widths[i])(x, x_gfs)\n",
    "                \n",
    "            skips.append(x)\n",
    "\n",
    "        if widths[i] != widths[-1]:\n",
    "            x = mu.DownSample(widths[i])(x)\n",
    "            skips.append(x)\n",
    "\n",
    "    # MiddleBlock\n",
    "    x = mu.ResidualBlock(widths[-1], groups=norm_groups, activation_fn=activation_fn)([x, temb])\n",
    "    \n",
    "    size_ = feature_sizes[-1]\n",
    "    x_gfs = gfs_input\n",
    "    x_gfs = layers.Resizing(size_, 2*size_, interpolation='bilinear')(x_gfs)\n",
    "    \n",
    "    x_gfs = layers.Conv2D(int(0.5*widths[-1]), kernel_size=(3, 3), padding=\"same\",)(x_gfs)\n",
    "    x_gfs = layers.GroupNormalization(groups=norm_groups)(x_gfs)\n",
    "    x_gfs = activation_fn(x_gfs)\n",
    "\n",
    "    x_gfs = layers.Conv2D(widths[-1], kernel_size=(3, 3), padding=\"same\",)(x_gfs)\n",
    "    x_gfs = layers.GroupNormalization(groups=norm_groups)(x_gfs)\n",
    "    x_gfs = activation_fn(x_gfs)\n",
    "    \n",
    "    x = layers.MultiHeadAttention(num_heads=norm_groups, key_dim=widths[-1])(x, x_gfs)\n",
    "    \n",
    "    x = mu.ResidualBlock(widths[-1], groups=norm_groups, activation_fn=activation_fn)([x, temb])\n",
    "\n",
    "    # UpBlock\n",
    "    has_attention = right_attention\n",
    "    for i in reversed(range(len(widths))):\n",
    "        for _ in range(num_res_blocks + 1):\n",
    "            x = layers.Concatenate(axis=-1)([x, skips.pop()])\n",
    "            x = mu.ResidualBlock(widths[i], groups=norm_groups, activation_fn=activation_fn)([x, temb])\n",
    "            \n",
    "            if has_attention[i]:\n",
    "                \n",
    "                # GFS cross-attention inputs\n",
    "                size_ = feature_sizes[i]\n",
    "                x_gfs = gfs_input\n",
    "                x_gfs = layers.Resizing(size_, 2*size_, interpolation='bilinear')(x_gfs)\n",
    "\n",
    "                x_gfs = layers.Conv2D(int(0.5*widths[i]), kernel_size=(3, 3), padding=\"same\",)(x_gfs)\n",
    "                x_gfs = layers.GroupNormalization(groups=norm_groups)(x_gfs)\n",
    "                x_gfs = activation_fn(x_gfs)\n",
    "\n",
    "                x_gfs = layers.Conv2D(widths[i], kernel_size=(3, 3), padding=\"same\",)(x_gfs)\n",
    "                x_gfs = layers.GroupNormalization(groups=norm_groups)(x_gfs)\n",
    "                x_gfs = activation_fn(x_gfs)\n",
    "                \n",
    "                x = layers.MultiHeadAttention(num_heads=norm_groups, key_dim=widths[i])(x, x_gfs)\n",
    "                \n",
    "        if i != 0:\n",
    "            x = mu.UpSample(widths[i], interpolation=interpolation)(x)\n",
    "\n",
    "    # End block\n",
    "    x = layers.GroupNormalization(groups=norm_groups)(x)\n",
    "    x = activation_fn(x)\n",
    "    x = layers.Conv2D(input_shape[-1], (3, 3), padding=\"same\", kernel_initializer=mu.kernel_init(0.0))(x)\n",
    "    return keras.Model([image_input, time_input, gfs_input], x, name=\"unet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c92957e-dd73-45bb-8fe2-8e03d40691ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse diffusino model\n",
    "model = build_model(input_shape=input_shape, gfs_shape=gfs_shape, widths=widths, \n",
    "                    feature_sizes=feature_sizes, left_attention=left_attention, right_attention=right_attention, \n",
    "                    num_res_blocks=num_res_blocks, norm_groups=norm_groups, activation_fn=keras.activations.swish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f74d3cfe-9ea6-4a98-a715-2813ecfe6d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the mdoel\n",
    "model.compile(loss=keras.losses.MeanAbsoluteError(), optimizer=keras.optimizers.Adam(learning_rate=lr),)\n",
    "\n",
    "# load previous weights\n",
    "if load_weights:\n",
    "    W_old = mu.dummy_loader(model_name)\n",
    "    model.set_weights(W_old)\n",
    "\n",
    "# configure the forward diffusion steps\n",
    "gdf_util = mu.GaussianDiffusion(timesteps=total_timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad250c4-f0c7-433b-b2e0-b66172ce092e",
   "metadata": {},
   "source": [
    "## Validation set preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ab3d4c6-80c1-42df-a6aa-eed53a1d0954",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_valid = 270 # number of validation samples\n",
    "\n",
    "# locations of training data\n",
    "BATCH_dir = '/glade/campaign/cisl/aiml/ksha/BATCH_LDM_025/'\n",
    "\n",
    "# preparing training batches\n",
    "filenames = np.array(sorted(glob(BATCH_dir+'*2023*.npy')))\n",
    "\n",
    "L = len(filenames)\n",
    "filename_valid = filenames[::50][:L_valid]\n",
    "\n",
    "Y_valid = np.empty((L_valid,)+input_shape)\n",
    "X_valid = np.empty((L_valid,)+gfs_shape)\n",
    "\n",
    "for i, name in enumerate(filename_valid):\n",
    "    temp_data = np.load(name, allow_pickle=True)[()]\n",
    "    X_valid[i, ...] = temp_data['GFS']\n",
    "    Y_valid[i, ...] = 2*(temp_data['MRMS']/precip_max-0.5)\n",
    "Y_valid[Y_valid>1.0] = 1.0\n",
    "\n",
    "# validate on random timesteps\n",
    "t_valid_ = np.random.uniform(low=0, high=total_timesteps, size=(L_valid,))\n",
    "t_valid = t_valid_.astype(int)\n",
    "\n",
    "# sample random noise to be added to the images in the batch\n",
    "noise_valid = np.random.normal(size=((L_valid,)+input_shape))\n",
    "images_valid = np.array(gdf_util.q_sample(Y_valid, t_valid, noise_valid))\n",
    "\n",
    "# validation prediction example:\n",
    "# pred_noise = model.predict([images_valid, t_valid, X_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e61fdae-5c01-4681-b152-19b01f9d8dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 124s 14s/step\n",
      "Initial validation loss: 0.03732102262436367\n"
     ]
    }
   ],
   "source": [
    "pred_noise = model.predict([images_valid, t_valid, X_valid])\n",
    "record = np.mean(np.abs(noise_valid - pred_noise))\n",
    "print('Initial validation loss: {}'.format(record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7466eada-7bd1-4ce1-9acb-c4bdc529a366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ecae65-4df4-439b-b036-ce063af6bcea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d8d6a1a-9388-4084-aaee-060533487a88",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce25956e-3e89-4cd1-b827-1bbcfd615c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all training batches\n",
    "filename_train1 = sorted(glob(BATCH_dir+'*2021*.npy'))\n",
    "filename_train2 = sorted(glob(BATCH_dir+'*2022*.npy'))\n",
    "\n",
    "filename_train = list(filename_train1) + list(filename_train2)\n",
    "L_train = len(filename_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "672fdabe-ff5a-4988-a02b-d82392615474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0\n",
      "9/9 [==============================] - 5s 515ms/step\n",
      "Initial validation loss: 0.03988743426908134\n",
      "9/9 [==============================] - 4s 514ms/step\n",
      "Validation loss improved from 0.03988743426908134 to 0.0380500046397584\n",
      "Save to /glade/work/ksha/GAN/models/LDM_025_resize2-2_res2_tune0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 222). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 382.7728805541992 seconds ---\n",
      "epoch = 1\n",
      "9/9 [==============================] - 5s 522ms/step\n",
      "Validation loss improved from 0.0380500046397584 to 0.03803164265120117\n",
      "Save to /glade/work/ksha/GAN/models/LDM_025_resize2-2_res2_tune0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 222). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 382.5710651874542 seconds ---\n",
      "epoch = 2\n",
      "9/9 [==============================] - 5s 516ms/step\n",
      "Validation loss 0.038082282364895255 NOT improved\n",
      "--- 297.5637457370758 seconds ---\n",
      "epoch = 3\n",
      "9/9 [==============================] - 5s 517ms/step\n",
      "Validation loss 0.03804873609656813 NOT improved\n",
      "--- 297.39590787887573 seconds ---\n",
      "epoch = 4\n",
      "9/9 [==============================] - 5s 516ms/step\n",
      "Validation loss improved from 0.03803164265120117 to 0.03791200756951528\n",
      "Save to /glade/work/ksha/GAN/models/LDM_025_resize2-2_res2_tune0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 222). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 390.5275945663452 seconds ---\n",
      "epoch = 5\n",
      "9/9 [==============================] - 5s 517ms/step\n",
      "Validation loss 0.037970427600414934 NOT improved\n",
      "--- 301.19238090515137 seconds ---\n",
      "epoch = 6\n",
      "9/9 [==============================] - 5s 516ms/step\n",
      "Validation loss improved from 0.03791200756951528 to 0.03779376910423886\n",
      "Save to /glade/work/ksha/GAN/models/LDM_025_resize2-2_res2_tune0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 222). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 389.1069667339325 seconds ---\n",
      "epoch = 7\n",
      "9/9 [==============================] - 5s 516ms/step\n",
      "Validation loss improved from 0.03779376910423886 to 0.03773410468035273\n",
      "Save to /glade/work/ksha/GAN/models/LDM_025_resize2-2_res2_tune0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 222). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 392.3885190486908 seconds ---\n",
      "epoch = 8\n",
      "9/9 [==============================] - 4s 514ms/step\n",
      "Validation loss 0.037864383583463314 NOT improved\n",
      "--- 299.65380096435547 seconds ---\n",
      "epoch = 9\n",
      "9/9 [==============================] - 5s 517ms/step\n",
      "Validation loss 0.037972250496816656 NOT improved\n",
      "--- 332.04002714157104 seconds ---\n",
      "epoch = 10\n",
      "9/9 [==============================] - 5s 515ms/step\n",
      "Validation loss 0.03773697903432527 NOT improved\n",
      "--- 335.9906802177429 seconds ---\n",
      "epoch = 11\n",
      "9/9 [==============================] - 4s 513ms/step\n",
      "Validation loss 0.03775461290422561 NOT improved\n",
      "--- 336.6466872692108 seconds ---\n",
      "epoch = 12\n",
      "9/9 [==============================] - 5s 515ms/step\n",
      "Validation loss improved from 0.03773410468035273 to 0.03771438653474483\n",
      "Save to /glade/work/ksha/GAN/models/LDM_025_resize2-2_res2_tune0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 222). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 425.84297943115234 seconds ---\n",
      "epoch = 13\n",
      "9/9 [==============================] - 5s 515ms/step\n",
      "Validation loss improved from 0.03771438653474483 to 0.03766659332805671\n",
      "Save to /glade/work/ksha/GAN/models/LDM_025_resize2-2_res2_tune0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 222). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 392.3420763015747 seconds ---\n",
      "epoch = 14\n",
      "9/9 [==============================] - 4s 513ms/step\n",
      "Validation loss 0.03769522034551742 NOT improved\n",
      "--- 300.34046173095703 seconds ---\n",
      "epoch = 15\n",
      "9/9 [==============================] - 4s 512ms/step\n",
      "Validation loss 0.037682053005707795 NOT improved\n",
      "--- 302.8091037273407 seconds ---\n",
      "epoch = 16\n",
      "9/9 [==============================] - 4s 512ms/step\n",
      "Validation loss improved from 0.03766659332805671 to 0.03763868403768055\n",
      "Save to /glade/work/ksha/GAN/models/LDM_025_resize2-2_res2_tune0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 222). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 383.5532786846161 seconds ---\n",
      "epoch = 17\n",
      "9/9 [==============================] - 4s 510ms/step\n",
      "Validation loss 0.03770679710404308 NOT improved\n",
      "--- 296.2361342906952 seconds ---\n",
      "epoch = 18\n",
      "9/9 [==============================] - 4s 511ms/step\n",
      "Validation loss 0.037828993398880656 NOT improved\n",
      "--- 296.36062002182007 seconds ---\n",
      "epoch = 19\n",
      "9/9 [==============================] - 4s 512ms/step\n",
      "Validation loss 0.037674154394488624 NOT improved\n",
      "--- 297.7257604598999 seconds ---\n",
      "epoch = 20\n",
      "9/9 [==============================] - 4s 512ms/step\n",
      "Validation loss 0.03772923930487647 NOT improved\n",
      "--- 294.6773455142975 seconds ---\n",
      "epoch = 21\n",
      "9/9 [==============================] - 4s 510ms/step\n",
      "Validation loss 0.037674720951792716 NOT improved\n",
      "--- 297.32176780700684 seconds ---\n",
      "epoch = 22\n",
      "9/9 [==============================] - 4s 511ms/step\n",
      "Validation loss 0.037683050349037864 NOT improved\n",
      "--- 297.3580901622772 seconds ---\n",
      "epoch = 23\n",
      "9/9 [==============================] - 4s 510ms/step\n",
      "Validation loss 0.03775688922706251 NOT improved\n",
      "--- 294.47267603874207 seconds ---\n",
      "epoch = 24\n",
      "9/9 [==============================] - 4s 510ms/step\n",
      "Validation loss improved from 0.03763868403768055 to 0.03760060109912628\n",
      "Save to /glade/work/ksha/GAN/models/LDM_025_resize2-2_res2_tune0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 222). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 383.90272068977356 seconds ---\n",
      "epoch = 25\n",
      "9/9 [==============================] - 4s 513ms/step\n",
      "Validation loss improved from 0.03760060109912628 to 0.03754288937130601\n",
      "Save to /glade/work/ksha/GAN/models/LDM_025_resize2-2_res2_tune0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 222). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 386.18426036834717 seconds ---\n",
      "epoch = 26\n",
      "9/9 [==============================] - 4s 510ms/step\n",
      "Validation loss 0.0376096670996019 NOT improved\n",
      "--- 296.6584937572479 seconds ---\n",
      "epoch = 27\n",
      "9/9 [==============================] - 4s 509ms/step\n",
      "Validation loss 0.037572997252047234 NOT improved\n",
      "--- 297.3257749080658 seconds ---\n",
      "epoch = 28\n",
      "9/9 [==============================] - 5s 511ms/step\n",
      "Validation loss 0.03759963143971753 NOT improved\n",
      "--- 301.20568323135376 seconds ---\n",
      "epoch = 29\n",
      "9/9 [==============================] - 4s 510ms/step\n",
      "Validation loss 0.03758376156950309 NOT improved\n",
      "--- 294.9192633628845 seconds ---\n",
      "epoch = 30\n",
      "9/9 [==============================] - 4s 511ms/step\n",
      "Validation loss 0.03754526525729822 NOT improved\n",
      "--- 295.3470706939697 seconds ---\n",
      "epoch = 31\n",
      "9/9 [==============================] - 4s 510ms/step\n",
      "Validation loss improved from 0.03754288937130601 to 0.03752749322464404\n",
      "Save to /glade/work/ksha/GAN/models/LDM_025_resize2-2_res2_tune0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 222). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 384.0536425113678 seconds ---\n",
      "epoch = 32\n",
      "9/9 [==============================] - 4s 511ms/step\n",
      "Validation loss 0.03770271384550706 NOT improved\n",
      "--- 298.57740092277527 seconds ---\n",
      "epoch = 33\n",
      "9/9 [==============================] - 4s 511ms/step\n",
      "Validation loss improved from 0.03752749322464404 to 0.03750192241173372\n",
      "Save to /glade/work/ksha/GAN/models/LDM_025_resize2-2_res2_tune0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 222). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 385.98226165771484 seconds ---\n",
      "epoch = 34\n",
      "9/9 [==============================] - 4s 510ms/step\n",
      "Validation loss 0.037529787594636016 NOT improved\n",
      "--- 300.5511803627014 seconds ---\n",
      "epoch = 35\n",
      "9/9 [==============================] - 4s 508ms/step\n",
      "Validation loss 0.037693698806163786 NOT improved\n",
      "--- 295.3760747909546 seconds ---\n",
      "epoch = 36\n",
      "9/9 [==============================] - 4s 510ms/step\n",
      "Validation loss 0.03750600624327547 NOT improved\n",
      "--- 297.4278745651245 seconds ---\n",
      "epoch = 37\n",
      "9/9 [==============================] - 4s 510ms/step\n",
      "Validation loss 0.03752657496150639 NOT improved\n",
      "--- 295.6003723144531 seconds ---\n",
      "epoch = 38\n",
      "9/9 [==============================] - 4s 510ms/step\n",
      "Validation loss 0.03753569661324586 NOT improved\n",
      "--- 295.9379518032074 seconds ---\n",
      "epoch = 39\n",
      "9/9 [==============================] - 5s 518ms/step\n",
      "Validation loss 0.037607024348616874 NOT improved\n",
      "--- 298.5415894985199 seconds ---\n",
      "epoch = 40\n",
      "9/9 [==============================] - 4s 510ms/step\n",
      "Validation loss improved from 0.03750192241173372 to 0.03747706681756768\n",
      "Save to /glade/work/ksha/GAN/models/LDM_025_resize2-2_res2_tune0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 222). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 386.8579885959625 seconds ---\n",
      "epoch = 41\n",
      "9/9 [==============================] - 4s 511ms/step\n",
      "Validation loss 0.037497681214874526 NOT improved\n",
      "--- 301.0545971393585 seconds ---\n",
      "epoch = 42\n",
      "9/9 [==============================] - 4s 511ms/step\n",
      "Validation loss 0.03754681501005251 NOT improved\n",
      "--- 297.5281147956848 seconds ---\n",
      "epoch = 43\n",
      "9/9 [==============================] - 4s 513ms/step\n",
      "Validation loss 0.037592518373314524 NOT improved\n",
      "--- 293.6817219257355 seconds ---\n",
      "epoch = 44\n",
      "9/9 [==============================] - 4s 512ms/step\n",
      "Validation loss improved from 0.03747706681756768 to 0.037454468644935\n",
      "Save to /glade/work/ksha/GAN/models/LDM_025_resize2-2_res2_tune0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 222). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 384.72926354408264 seconds ---\n",
      "epoch = 45\n",
      "9/9 [==============================] - 4s 510ms/step\n",
      "Validation loss improved from 0.037454468644935 to 0.03745314544872295\n",
      "Save to /glade/work/ksha/GAN/models/LDM_025_resize2-2_res2_tune0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 222). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 387.77791953086853 seconds ---\n",
      "epoch = 46\n",
      "9/9 [==============================] - 4s 514ms/step\n",
      "Validation loss 0.03746416163979841 NOT improved\n",
      "--- 295.92307782173157 seconds ---\n",
      "epoch = 47\n",
      "9/9 [==============================] - 4s 511ms/step\n",
      "Validation loss 0.03749742092325636 NOT improved\n",
      "--- 296.7400915622711 seconds ---\n",
      "epoch = 48\n",
      "9/9 [==============================] - 4s 511ms/step\n",
      "Validation loss 0.03758099301620717 NOT improved\n",
      "--- 297.82272505760193 seconds ---\n",
      "epoch = 49\n",
      "9/9 [==============================] - 4s 509ms/step\n",
      "Validation loss improved from 0.03745314544872295 to 0.037444059330715554\n",
      "Save to /glade/work/ksha/GAN/models/LDM_025_resize2-2_res2_tune0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 222). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 391.40760827064514 seconds ---\n",
      "epoch = 50\n",
      "9/9 [==============================] - 4s 512ms/step\n",
      "Validation loss 0.0374765976132695 NOT improved\n",
      "--- 293.94353675842285 seconds ---\n",
      "epoch = 51\n",
      "9/9 [==============================] - 4s 511ms/step\n",
      "Validation loss improved from 0.037444059330715554 to 0.03741259305204699\n",
      "Save to /glade/work/ksha/GAN/models/LDM_025_resize2-2_res2_tune0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 222). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 389.63240480422974 seconds ---\n",
      "epoch = 52\n",
      "9/9 [==============================] - 4s 514ms/step\n",
      "Validation loss 0.037487177403142315 NOT improved\n",
      "--- 294.58331966400146 seconds ---\n",
      "epoch = 53\n",
      "9/9 [==============================] - 5s 515ms/step\n",
      "Validation loss 0.03751557034900253 NOT improved\n",
      "--- 315.0151665210724 seconds ---\n",
      "epoch = 54\n",
      "9/9 [==============================] - 4s 510ms/step\n",
      "Validation loss 0.0374561430247498 NOT improved\n",
      "--- 326.33166241645813 seconds ---\n",
      "epoch = 55\n",
      "9/9 [==============================] - 4s 509ms/step\n",
      "Validation loss 0.03744267445695326 NOT improved\n",
      "--- 319.8150351047516 seconds ---\n",
      "epoch = 56\n",
      "9/9 [==============================] - 4s 513ms/step\n",
      "Validation loss 0.037419891659404285 NOT improved\n",
      "--- 323.64186334609985 seconds ---\n",
      "epoch = 57\n",
      "9/9 [==============================] - 5s 519ms/step\n",
      "Validation loss 0.03744828809864342 NOT improved\n",
      "--- 339.11074018478394 seconds ---\n",
      "epoch = 58\n",
      "9/9 [==============================] - 5s 516ms/step\n",
      "Validation loss improved from 0.03741259305204699 to 0.0374032875362101\n",
      "Save to /glade/work/ksha/GAN/models/LDM_025_resize2-2_res2_tune0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 222). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 444.6967821121216 seconds ---\n",
      "epoch = 59\n",
      "9/9 [==============================] - 4s 511ms/step\n",
      "Validation loss improved from 0.0374032875362101 to 0.037392658476622424\n",
      "Save to /glade/work/ksha/GAN/models/LDM_025_resize2-2_res2_tune0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 222). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 387.87478137016296 seconds ---\n",
      "epoch = 60\n",
      "9/9 [==============================] - 4s 509ms/step\n",
      "Validation loss improved from 0.037392658476622424 to 0.03734908431437221\n",
      "Save to /glade/work/ksha/GAN/models/LDM_025_resize2-2_res2_tune0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 222). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 378.3278024196625 seconds ---\n",
      "epoch = 61\n",
      "9/9 [==============================] - 4s 513ms/step\n",
      "Validation loss 0.037647692135827596 NOT improved\n",
      "--- 293.97376108169556 seconds ---\n",
      "epoch = 62\n",
      "9/9 [==============================] - 4s 510ms/step\n",
      "Validation loss 0.03755404850895701 NOT improved\n",
      "--- 301.7577579021454 seconds ---\n",
      "epoch = 63\n",
      "9/9 [==============================] - 4s 511ms/step\n",
      "Validation loss 0.037470603347100444 NOT improved\n",
      "--- 292.3572111129761 seconds ---\n",
      "epoch = 64\n",
      "9/9 [==============================] - 4s 509ms/step\n",
      "Validation loss 0.03741101800811885 NOT improved\n",
      "--- 292.819237947464 seconds ---\n",
      "epoch = 65\n",
      "9/9 [==============================] - 4s 511ms/step\n",
      "Validation loss 0.03746211377164849 NOT improved\n",
      "--- 293.39149713516235 seconds ---\n",
      "epoch = 66\n",
      "9/9 [==============================] - 4s 510ms/step\n",
      "Validation loss improved from 0.03734908431437221 to 0.03734062143556079\n",
      "Save to /glade/work/ksha/GAN/models/LDM_025_resize2-2_res2_tune0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 222). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 382.38566064834595 seconds ---\n",
      "epoch = 67\n",
      "9/9 [==============================] - 5s 514ms/step\n",
      "Validation loss 0.03739866049203444 NOT improved\n",
      "--- 291.934175491333 seconds ---\n",
      "epoch = 68\n",
      "9/9 [==============================] - 4s 511ms/step\n",
      "Validation loss 0.03741834614761141 NOT improved\n",
      "--- 291.6418402194977 seconds ---\n",
      "epoch = 69\n",
      "9/9 [==============================] - 4s 510ms/step\n",
      "Validation loss 0.03756266722191525 NOT improved\n",
      "--- 292.12633633613586 seconds ---\n",
      "epoch = 70\n",
      "9/9 [==============================] - 5s 518ms/step\n",
      "Validation loss 0.03746798557970368 NOT improved\n",
      "--- 292.5692365169525 seconds ---\n",
      "epoch = 71\n",
      "9/9 [==============================] - 4s 514ms/step\n",
      "Validation loss 0.03740182692049369 NOT improved\n",
      "--- 293.3640570640564 seconds ---\n",
      "epoch = 72\n",
      "9/9 [==============================] - 5s 515ms/step\n",
      "Validation loss improved from 0.03734062143556079 to 0.03731325856988152\n",
      "Save to /glade/work/ksha/GAN/models/LDM_025_resize2-2_res2_tune0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 222). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 390.8638813495636 seconds ---\n",
      "epoch = 73\n",
      "9/9 [==============================] - 4s 509ms/step\n",
      "Validation loss 0.037437789804464966 NOT improved\n",
      "--- 288.0594472885132 seconds ---\n",
      "epoch = 74\n",
      "9/9 [==============================] - 4s 510ms/step\n",
      "Validation loss 0.037330492684992965 NOT improved\n",
      "--- 290.8726146221161 seconds ---\n",
      "epoch = 75\n",
      "9/9 [==============================] - 4s 513ms/step\n",
      "Validation loss 0.037331965022318246 NOT improved\n",
      "--- 296.05985856056213 seconds ---\n",
      "epoch = 76\n",
      "9/9 [==============================] - 4s 509ms/step\n",
      "Validation loss 0.037347612171833106 NOT improved\n",
      "--- 337.36700463294983 seconds ---\n",
      "epoch = 77\n",
      "9/9 [==============================] - 4s 513ms/step\n",
      "Validation loss 0.03732851835413321 NOT improved\n",
      "--- 348.5465364456177 seconds ---\n",
      "epoch = 78\n",
      "9/9 [==============================] - 4s 513ms/step\n",
      "Validation loss 0.037377768241974356 NOT improved\n",
      "--- 297.9385120868683 seconds ---\n",
      "epoch = 79\n",
      "9/9 [==============================] - 4s 514ms/step\n",
      "Validation loss 0.03750843675827367 NOT improved\n",
      "--- 297.58144640922546 seconds ---\n",
      "epoch = 80\n",
      "9/9 [==============================] - 4s 514ms/step\n",
      "Validation loss improved from 0.03731325856988152 to 0.037308217414540226\n",
      "Save to /glade/work/ksha/GAN/models/LDM_025_resize2-2_res2_tune0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 222). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 387.1082637310028 seconds ---\n",
      "epoch = 81\n",
      "9/9 [==============================] - 4s 513ms/step\n",
      "Validation loss 0.037472838707092296 NOT improved\n",
      "--- 293.94818329811096 seconds ---\n",
      "epoch = 82\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m     images_t \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(gdf_util\u001b[38;5;241m.\u001b[39mq_sample(Y_batch, t, noise))\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# train on batch\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimages_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# on epoch-end\u001b[39;00m\n\u001b[1;32m     45\u001b[0m pred_noise \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict([images_valid, t_valid, X_valid])\n",
      "File \u001b[0;32m/glade/work/ksha/conda-envs/tf212gpu/lib/python3.10/site-packages/keras/engine/training.py:2510\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   2506\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39msingle_batch_iterator(\n\u001b[1;32m   2507\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, x, y, sample_weight, class_weight\n\u001b[1;32m   2508\u001b[0m     )\n\u001b[1;32m   2509\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_function()\n\u001b[0;32m-> 2510\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2512\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[0;32m/glade/work/ksha/conda-envs/tf212gpu/lib/python3.10/site-packages/keras/engine/training.py:1284\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_function\u001b[39m(iterator):\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstep_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/ksha/conda-envs/tf212gpu/lib/python3.10/site-packages/keras/engine/training.py:1268\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1264\u001b[0m     run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[1;32m   1265\u001b[0m         run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1266\u001b[0m     )\n\u001b[1;32m   1267\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[0;32m-> 1268\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1269\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[1;32m   1270\u001b[0m     outputs,\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[1;32m   1272\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_reduction_method,\n\u001b[1;32m   1273\u001b[0m )\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/glade/work/ksha/conda-envs/tf212gpu/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:1316\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m   1312\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1314\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   1315\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1316\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/ksha/conda-envs/tf212gpu/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:2895\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2893\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   2894\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 2895\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/ksha/conda-envs/tf212gpu/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3696\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3694\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   3695\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m-> 3696\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/ksha/conda-envs/tf212gpu/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:595\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    594\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mUNSPECIFIED):\n\u001b[0;32m--> 595\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/ksha/conda-envs/tf212gpu/lib/python3.10/site-packages/keras/engine/training.py:1249\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[0;32m-> 1249\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[0;32m/glade/work/ksha/conda-envs/tf212gpu/lib/python3.10/site-packages/keras/engine/training.py:1054\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# Run backwards pass.\u001b[39;00m\n\u001b[0;32m-> 1054\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[0;32m/glade/work/ksha/conda-envs/tf212gpu/lib/python3.10/site-packages/keras/optimizers/optimizer.py:542\u001b[0m, in \u001b[0;36m_BaseOptimizer.minimize\u001b[0;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mminimize\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss, var_list, tape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    522\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \n\u001b[1;32m    524\u001b[0m \u001b[38;5;124;03m    This method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03m      None\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 542\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_gradients(grads_and_vars)\n",
      "File \u001b[0;32m/glade/work/ksha/conda-envs/tf212gpu/lib/python3.10/site-packages/keras/optimizers/optimizer.py:275\u001b[0m, in \u001b[0;36m_BaseOptimizer.compute_gradients\u001b[0;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(var_list):\n\u001b[1;32m    273\u001b[0m             var_list \u001b[38;5;241m=\u001b[39m var_list()\n\u001b[0;32m--> 275\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, var_list))\n",
      "File \u001b[0;32m/glade/work/ksha/conda-envs/tf212gpu/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py:1063\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1057\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1058\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m   1059\u001b[0m           output_gradients))\n\u001b[1;32m   1060\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m   1061\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[0;32m-> 1063\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[1;32m   1072\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[0;32m/glade/work/ksha/conda-envs/tf212gpu/lib/python3.10/site-packages/tensorflow/python/eager/imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/ksha/conda-envs/tf212gpu/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py:146\u001b[0m, in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    144\u001b[0m     gradient_name_scope \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m forward_pass_name_scope \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmock_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n",
      "File \u001b[0;32m/glade/work/ksha/conda-envs/tf212gpu/lib/python3.10/site-packages/tensorflow/python/ops/math_grad.py:262\u001b[0m, in \u001b[0;36m_MeanGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    259\u001b[0m   output_shape \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mshape(op\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    260\u001b[0m   factor \u001b[38;5;241m=\u001b[39m _safe_shape_div(\n\u001b[1;32m    261\u001b[0m       math_ops\u001b[38;5;241m.\u001b[39mreduce_prod(input_shape), math_ops\u001b[38;5;241m.\u001b[39mreduce_prod(output_shape))\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m math_ops\u001b[38;5;241m.\u001b[39mtruediv(sum_grad, \u001b[43mmath_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfactor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msum_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m), \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/glade/work/ksha/conda-envs/tf212gpu/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/glade/work/ksha/conda-envs/tf212gpu/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1170\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iterable_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1169\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m replace_iterable_params(args, kwargs, iterable_params)\n\u001b[0;32m-> 1170\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mapi_dispatcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1172\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "min_del = 0.0\n",
    "max_tol = 3 # early stopping with 2-epoch patience\n",
    "tol = 0\n",
    "\n",
    "Y_batch = np.empty((batch_size,)+input_shape)\n",
    "X_batch = np.empty((batch_size,)+gfs_shape)\n",
    "\n",
    "for i in range(epochs):    \n",
    "    print('epoch = {}'.format(i))\n",
    "    if i == 0:\n",
    "        pred_noise = model.predict([images_valid, t_valid, X_valid])\n",
    "        record = np.mean(np.abs(noise_valid - pred_noise))\n",
    "        #print('initial loss {}'.format(record))\n",
    "        print('Initial validation loss: {}'.format(record))\n",
    "        \n",
    "    start_time = time.time()\n",
    "    # loop over batches\n",
    "    for j in range(N_batch):\n",
    "        \n",
    "        inds_rnd = du.shuffle_ind(L_train) # shuffle training files\n",
    "        inds_ = inds_rnd[:batch_size] # select training files\n",
    "        \n",
    "        # collect training batches\n",
    "        for k, ind in enumerate(inds_):\n",
    "            # import batch data\n",
    "            temp_name = filename_train[ind]\n",
    "            temp_data = np.load(temp_name, allow_pickle=True)[()]\n",
    "            X_batch[k, ...] = temp_data['GFS']\n",
    "            Y_batch[k, ...] = 2*(temp_data['MRMS']/precip_max-0.5)\n",
    "            \n",
    "        Y_batch[Y_batch>1.0] = 1.0\n",
    "\n",
    "        # sample timesteps uniformly\n",
    "        t_ = np.random.uniform(low=0, high=total_timesteps, size=(batch_size,))\n",
    "        t = t_.astype(int)\n",
    "        \n",
    "        # sample random noise to be added to the images in the batch\n",
    "        noise = np.random.normal(size=(batch_size,)+input_shape)\n",
    "        images_t = np.array(gdf_util.q_sample(Y_batch, t, noise))\n",
    "        \n",
    "        # train on batch\n",
    "        model.train_on_batch([images_t, t, X_batch], noise)\n",
    "        \n",
    "    # on epoch-end\n",
    "    pred_noise = model.predict([images_valid, t_valid, X_valid])\n",
    "    record_temp = np.mean(np.abs(noise_valid - pred_noise))\n",
    "    \n",
    "    # print out valid loss change\n",
    "    if record - record_temp > min_del:\n",
    "        print('Validation loss improved from {} to {}'.format(record, record_temp))\n",
    "        record = record_temp\n",
    "        print(\"Save to {}\".format(model_name_save))\n",
    "        model.save(model_name_save)\n",
    "        \n",
    "    else:\n",
    "        print('Validation loss {} NOT improved'.format(record_temp))\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    # mannual callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b911c0-7857-488e-803b-4b46c0e56285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d58b8380-33dc-4ee8-8e37-633a59ca93bc",
   "metadata": {},
   "source": [
    "## Plot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dbd6b2-7df8-4ce1-b026-a199214d499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8079dbea-f1ee-4e8f-b261-5d0170544e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 190ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_noise = model.predict([images_valid, t_valid, X_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce1592c-8cce-4f93-90db-ed28555065f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2699905-c445-4547-8f4d-5d5718e8f738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_diffuse(model, x_in1, x_in2, total_timesteps, gdf_util):\n",
    "    L_valid = len(x_in1)\n",
    "    x_out = np.empty(x_in1.shape)\n",
    "\n",
    "    for i in range(L_valid):\n",
    "        x1 = x_in1[i, ...][None, ...]\n",
    "        x2 = x_in2[i, ...][None, ...]\n",
    "        \n",
    "        for t in reversed(range(0, total_timesteps)):\n",
    "            tt = tf.cast(tf.fill(1, t), dtype=tf.int64)\n",
    "            pred_noise = model.predict([x1, tt, x2], verbose=0)\n",
    "            model_mean, _, model_log_variance =  gdf_util.p_mean_variance(pred_noise, x=x1, t=tt, clip_denoised=True)\n",
    "            nonzero_mask = (1 - (np.array(tt)==0)).reshape((1, 1, 1, 1))\n",
    "            x1 = np.array(model_mean) + nonzero_mask * np.exp(0.5 * np.array(model_log_variance)) * np.random.normal(size=x1.shape)\n",
    "        x_out[i, ...] = x1\n",
    "\n",
    "    return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b77071-8d60-434b-a2c5-90e83fca800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "# Y_pred = reverse_diffuse(model, images_valid, X_valid, total_timesteps, gdf_util)\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73dd666-069d-4c45-865b-dd6078218ce5",
   "metadata": {},
   "source": [
    "**out-of-box reverse diffusion tests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103eb489-8a3c-431c-bca9-2dc2f6ba585c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_in1 = images_valid\n",
    "# x_in2 = X_valid\n",
    "\n",
    "# x1 = x_in1[i, ...][None, ...]\n",
    "# x2 = x_in2[i, ...][None, ...]\n",
    "        \n",
    "# for t in reversed(range(0, total_timesteps)):\n",
    "#     tt = tf.cast(tf.fill(1, t), dtype=tf.int64)\n",
    "#     pred_noise = model.predict([x1, tt, x2], verbose=0)\n",
    "#     model_mean, _, model_log_variance =  gdf_util.p_mean_variance(pred_noise, x=x1, t=tt, clip_denoised=True)\n",
    "#     nonzero_mask = (1 - (np.array(tt)==0)).reshape((1, 1, 1, 1))\n",
    "#     x1 = np.array(model_mean) + nonzero_mask * np.exp(0.5 * np.array(model_log_variance)) * np.random.normal(size=x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784a2f2f-521a-4c16-9dbb-01cf795c9dac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
