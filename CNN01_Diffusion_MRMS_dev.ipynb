{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be9e3879-4f41-4ecd-a1d8-aed79a990e23",
   "metadata": {},
   "source": [
    "# Unconditioned diffusion model on MRMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db0f355b-2a2f-455f-935b-81bd280523cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import logging\n",
    "import warnings\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# supress regular warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR) \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# supress tensorflow warnings\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# adjust for time step embedding layer\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a22dad1-ec77-48b2-9150-fb81faf102ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/glade/u/home/ksha/GAN_proj/')\n",
    "sys.path.insert(0, '/glade/u/home/ksha/GAN_proj/libs/')\n",
    "\n",
    "from namelist import *\n",
    "import data_utils as du\n",
    "import model_utils as mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfa9604-6e74-41b6-b87f-26ab011c2643",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7286b304-35ed-444b-8512-90c541d7ae4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_timesteps = 50 # diffusion time steps\n",
    "norm_groups = 8 # number of attention heads, number of layer normalization groups \n",
    "\n",
    "# min-max values of the diffusion target (learning target) \n",
    "clip_min = -1.0\n",
    "clip_max = 1.0\n",
    "\n",
    "widths = [16, 32, 48, 64] # number of convolution kernels per up-/downsampling level\n",
    "left_attention = [False, False, True, True] # True: use multi-head attnetion on each up-/downsampling level\n",
    "right_attention = [False, False, True, True]\n",
    "num_res_blocks = 1  # Number of residual blocks\n",
    "\n",
    "input_shape = (128, 128, 2) # the tensor shape of reverse diffusion input\n",
    "\n",
    "load_weights = False # True: load previous weights\n",
    "\n",
    "# location of the previous weights\n",
    "model_name = '/glade/work/ksha/GAN/models/DM_example_base/'\n",
    "# location for saving new weights\n",
    "model_name_save = '/glade/work/ksha/GAN/models/DM_example_base/'\n",
    "\n",
    "lr = 1e-4 # learning rate\n",
    "\n",
    "# samples per epoch = N_batch * batch_size\n",
    "epochs = 99999\n",
    "N_batch = 128\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe9ad55-865c-40e3-bfd9-d252832d8e79",
   "metadata": {},
   "source": [
    "## Model design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b30c6292-34bc-4379-8a81-76c369b6d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, widths, left_attention, right_attention, num_res_blocks=2, norm_groups=8,\n",
    "                interpolation=\"nearest\", activation_fn=keras.activations.swish,):\n",
    "\n",
    "    first_conv_channels = widths[0]\n",
    "    \n",
    "    image_input = layers.Input(shape=input_shape, name=\"image_input\")\n",
    "    time_input = keras.Input(shape=(), dtype=tf.int64, name=\"time_input\")\n",
    "    \n",
    "    x = layers.Conv2D(first_conv_channels, kernel_size=(3, 3), padding=\"same\",\n",
    "                      kernel_initializer=mu.kernel_init(1.0),)(image_input)\n",
    "\n",
    "    temb = mu.TimeEmbedding(dim=first_conv_channels * 4)(time_input)\n",
    "    temb = mu.TimeMLP(units=first_conv_channels * 4, activation_fn=activation_fn)(temb)\n",
    "\n",
    "    skips = [x]\n",
    "\n",
    "    # DownBlock\n",
    "    has_attention = left_attention\n",
    "    for i in range(len(widths)):\n",
    "        for _ in range(num_res_blocks):\n",
    "            x = mu.ResidualBlock(widths[i], groups=norm_groups, activation_fn=activation_fn)([x, temb])\n",
    "            \n",
    "            if has_attention[i]:\n",
    "                x = layers.MultiHeadAttention(num_heads=norm_groups, key_dim=widths[i])(x, x)\n",
    "                \n",
    "            skips.append(x)\n",
    "\n",
    "        if widths[i] != widths[-1]:\n",
    "            x = mu.DownSample(widths[i])(x)\n",
    "            skips.append(x)\n",
    "\n",
    "    # MiddleBlock\n",
    "    x = mu.ResidualBlock(widths[-1], groups=norm_groups, activation_fn=activation_fn)([x, temb])\n",
    "    x = layers.MultiHeadAttention(num_heads=norm_groups, key_dim=widths[-1])(x, x)\n",
    "    x = mu.ResidualBlock(widths[-1], groups=norm_groups, activation_fn=activation_fn)([x, temb])\n",
    "\n",
    "    # UpBlock\n",
    "    has_attention = right_attention\n",
    "    for i in reversed(range(len(widths))):\n",
    "        for _ in range(num_res_blocks + 1):\n",
    "            x = layers.Concatenate(axis=-1)([x, skips.pop()])\n",
    "            x = mu.ResidualBlock(widths[i], groups=norm_groups, activation_fn=activation_fn)([x, temb])\n",
    "            \n",
    "            if has_attention[i]:\n",
    "                x = layers.MultiHeadAttention(num_heads=norm_groups, key_dim=widths[i])(x, x)\n",
    "\n",
    "        if i != 0:\n",
    "            x = mu.UpSample(widths[i], interpolation=interpolation)(x)\n",
    "\n",
    "    # End block\n",
    "    x = layers.GroupNormalization(groups=norm_groups)(x)\n",
    "    x = activation_fn(x)\n",
    "    x = layers.Conv2D(1, (3, 3), padding=\"same\", kernel_initializer=mu.kernel_init(0.0))(x)\n",
    "    return keras.Model([image_input, time_input], x, name=\"unet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "516dbb48-4261-4f51-96e8-fefb306dfd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse diffusino model\n",
    "model = build_model(input_shape=input_shape, widths=widths,\n",
    "                    left_attention=left_attention, right_attention=right_attention, \n",
    "                    num_res_blocks=num_res_blocks, norm_groups=norm_groups, activation_fn=keras.activations.swish)\n",
    "\n",
    "# Compile the mdoel\n",
    "model.compile(loss=keras.losses.MeanAbsoluteError(), optimizer=keras.optimizers.Adam(learning_rate=lr),)\n",
    "\n",
    "# load previous weights\n",
    "if load_weights:\n",
    "    W_old = mu.dummy_loader(model_name)\n",
    "    model.set_weights(W_old)\n",
    "\n",
    "# configure the forward diffusion steps\n",
    "gdf_util = mu.GaussianDiffusion(timesteps=total_timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f7030b-1cb5-4f7d-a4bf-2a42b9251d28",
   "metadata": {},
   "source": [
    "## Validation set preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e059c479-1131-4277-8d28-93f6fd439a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of training data\n",
    "BATCH_dir = '/glade/campaign/cisl/aiml/ksha/BATCH_GFS_VALID/'\n",
    "\n",
    "# validation set size\n",
    "L_valid = 500\n",
    "\n",
    "# collect validation set sampales\n",
    "filenames = np.array(sorted(glob(BATCH_dir+'*.npy')))\n",
    "filename_valid = filenames[::7][:L_valid]\n",
    "\n",
    "Y_valid = np.empty((L_valid,)+input_shape)\n",
    "\n",
    "for i, name in enumerate(filename_valid):\n",
    "    temp_data = np.load(name)\n",
    "    Y_valid[i, ...] = temp_data[0, ..., :2]\n",
    "\n",
    "# validate on random timesteps\n",
    "t_valid_ = np.random.uniform(low=0, high=total_timesteps, size=(L_valid,))\n",
    "t_valid = t_valid_.astype(int)\n",
    "\n",
    "# sample random noise to be added to the images in the batch\n",
    "noise_valid = np.random.normal(size=((L_valid,)+(128, 128, 1)))\n",
    "images_valid_ = np.array(gdf_util.q_sample(Y_valid[..., 0][..., None], t_valid, noise_valid))\n",
    "images_valid = np.concatenate((images_valid_, Y_valid[..., 1][..., None]), axis=-1)\n",
    "# # validation prediction example:\n",
    "# # pred_noise = model.predict([images_valid, t_valid, X_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f55ac8-780e-44cc-bfd9-cdc0a6e7cb9e",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03a38fa1-a339-41fd-a5a8-dcfb559e613d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect training samples\n",
    "BATCH_dir = '/glade/campaign/cisl/aiml/ksha/BATCH_GFS_MRMS/'\n",
    "filename_train = np.array(sorted(glob(BATCH_dir+'*.npy')))\n",
    "L_train = len(filename_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595d9a2e-64a5-4f9d-8a51-26b24a24e30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0\n",
      "16/16 [==============================] - 4s 195ms/step\n",
      "Initial validation loss: 0.7976657147197463\n"
     ]
    }
   ],
   "source": [
    "min_del = 0.0\n",
    "max_tol = 3 # early stopping with 2-epoch patience\n",
    "tol = 0\n",
    "\n",
    "Y_batch = np.empty((batch_size,)+input_shape)\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    print('epoch = {}'.format(i))\n",
    "    if i == 0:\n",
    "        pred_noise = model.predict([images_valid, t_valid])\n",
    "        record = np.mean(np.abs(noise_valid - pred_noise))\n",
    "        #print('initial loss {}'.format(record))\n",
    "        print('Initial validation loss: {}'.format(record))\n",
    "        \n",
    "    start_time = time.time()\n",
    "    # loop over batches\n",
    "    for j in range(N_batch):\n",
    "        \n",
    "        inds_rnd = du.shuffle_ind(L_train) # shuffle training files\n",
    "        inds_ = inds_rnd[:batch_size] # select training files\n",
    "        \n",
    "        # collect training batches\n",
    "        for k, ind in enumerate(inds_):\n",
    "            # import batch data\n",
    "            temp_name = filename_train[ind]\n",
    "            temp_data = np.load(temp_name)\n",
    "            Y_batch[i, ...] = temp_data[0, ..., :2]\n",
    "        \n",
    "        # sample timesteps uniformly\n",
    "        t_ = np.random.uniform(low=0, high=total_timesteps, size=(batch_size,))\n",
    "        t = t_.astype(int)\n",
    "        \n",
    "        # sample random noise to be added to the images in the batch\n",
    "        noise = np.random.normal(size=(batch_size,)+input_shape)\n",
    "        images_t = np.array(gdf_util.q_sample(Y_batch, t, noise))\n",
    "        \n",
    "        # sample random noise to be added to the images in the batch\n",
    "        noise = np.random.normal(size=((batch_size,)+(128, 128, 1)))\n",
    "        images_t_ = np.array(gdf_util.q_sample(Y_batch[..., 0][..., None], t, noise))\n",
    "        images_t = np.concatenate((images_t_, Y_batch[..., 1][..., None]), axis=-1)\n",
    "        \n",
    "        # train on batch\n",
    "        model.train_on_batch([images_t, t], noise)\n",
    "        \n",
    "    # on epoch-end\n",
    "    pred_noise = model.predict([images_valid, t_valid])\n",
    "    record_temp = np.mean(np.abs(noise_valid - pred_noise))\n",
    "    \n",
    "    # print out valid loss change\n",
    "    if record - record_temp > min_del:\n",
    "        print('Validation loss improved from {} to {}'.format(record, record_temp))\n",
    "        record = record_temp\n",
    "        print(\"Save to {}\".format(model_name_save))\n",
    "        model.save(model_name_save)\n",
    "        \n",
    "    else:\n",
    "        print('Validation loss {} NOT improved'.format(record_temp))\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    # mannual callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e594a9d-7d68-4c54-b3b4-b3ef8fc108ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cfdd5a-274f-46a8-a5cc-68ade37a7f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b955c05-827c-499e-9d4a-6ce6d0e92eba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b437111-3858-4ae1-be82-d31a8e4f6883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df36f025-353a-4f62-8589-ecf0807783a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
