{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7184eacc-7e1f-4419-b3c2-028a9009eff5",
   "metadata": {},
   "source": [
    "# Latent diffusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7a96452-c069-44e7-b60b-5df4228af9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import logging\n",
    "import warnings\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# supress regular warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR) \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# supress tensorflow warnings\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# adjust for time step embedding layer\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dccf289-82cc-4ba1-9067-5db5bd2920c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/glade/u/home/ksha/GAN_proj/')\n",
    "sys.path.insert(0, '/glade/u/home/ksha/GAN_proj/libs/')\n",
    "\n",
    "from namelist import *\n",
    "import data_utils as du\n",
    "import model_utils as mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08a1024-2a8f-4a29-b102-18f0ccbd9c4e",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdb55f36-d87a-4ffd-b7a7-0e447de69957",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_timesteps = 50 # diffusion time steps\n",
    "norm_groups = 8 # number of attention heads, number of layer normalization groups \n",
    "\n",
    "\n",
    "# min-max values of the diffusion target (learning target) \n",
    "clip_min = -1.0\n",
    "clip_max = 1.0\n",
    "\n",
    "widths = [64, 96, 128, 256] # number of convolution kernels per up-/downsampling level\n",
    "has_attention = [False, True, True, True] # True: use multi-head attnetion on each up-/downsampling level\n",
    "num_res_blocks = 2  # Number of residual blocks\n",
    "\n",
    "input_shape = (32, 32, 8) # the tensor shape of reverse diffusion input\n",
    "gfs_shape = (16, 16, 256) # the tensor shape of GFS embeddings\n",
    "\n",
    "F_x = 0.1 # the scale of GFS embeddings\n",
    "F_y = 1/2.76 # the scale of VQ-VAE codes\n",
    "\n",
    "N_atten = np.sum(has_attention)\n",
    "# location of the previous weights\n",
    "model_name = '/glade/work/ksha/GAN/models/LDM_atten{}_res{}_base/'.format(N_atten, num_res_blocks)\n",
    "\n",
    "lr = 0 # learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117e5f1c-85e9-41b5-b868-519e18b36da3",
   "metadata": {},
   "source": [
    "## Model design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c22ade0-b55b-4459-92cc-63f5ae335c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, gfs_shape, widths, has_attention, num_res_blocks=2, norm_groups=8,\n",
    "                interpolation=\"nearest\", activation_fn=keras.activations.swish,):\n",
    "\n",
    "    first_conv_channels = widths[0]\n",
    "    \n",
    "    image_input = layers.Input(shape=input_shape, name=\"image_input\")\n",
    "    time_input = keras.Input(shape=(), dtype=tf.int64, name=\"time_input\")\n",
    "    gfs_input = layers.Input(shape=gfs_shape, name=\"gfs_input\")\n",
    "    \n",
    "    x = layers.Conv2D(first_conv_channels, kernel_size=(3, 3), padding=\"same\",\n",
    "                      kernel_initializer=mu.kernel_init(1.0),)(image_input)\n",
    "\n",
    "    temb = mu.TimeEmbedding(dim=first_conv_channels * 4)(time_input)\n",
    "    temb = mu.TimeMLP(units=first_conv_channels * 4, activation_fn=activation_fn)(temb)\n",
    "\n",
    "    skips = [x]\n",
    "\n",
    "    # DownBlock\n",
    "    for i in range(len(widths)):\n",
    "        for _ in range(num_res_blocks):\n",
    "            x = mu.ResidualBlock(widths[i], groups=norm_groups, activation_fn=activation_fn)([x, temb])\n",
    "            \n",
    "            if has_attention[i]:\n",
    "                x_gfs = gfs_input\n",
    "                for _ in range(i-1):\n",
    "                    x_gfs = layers.Conv2D(widths[i], kernel_size=(2, 2), strides=2, padding=\"same\",)(x_gfs)\n",
    "                x = layers.MultiHeadAttention(num_heads=norm_groups, key_dim=widths[i])(x, x_gfs)\n",
    "                \n",
    "            skips.append(x)\n",
    "\n",
    "        if widths[i] != widths[-1]:\n",
    "            x = mu.DownSample(widths[i])(x)\n",
    "            skips.append(x)\n",
    "\n",
    "    # MiddleBlock\n",
    "    x = mu.ResidualBlock(widths[-1], groups=norm_groups, activation_fn=activation_fn)([x, temb])\n",
    "    \n",
    "    x_gfs = gfs_input\n",
    "    for _ in range(3):\n",
    "        x_gfs = layers.Conv2D(widths[i], kernel_size=(2, 2), strides=2, padding=\"same\",)(x_gfs)\n",
    "    x = layers.MultiHeadAttention(num_heads=norm_groups, key_dim=widths[i])(x, x_gfs)\n",
    "    x = layers.MultiHeadAttention(num_heads=norm_groups, key_dim=widths[-1])(x, x_gfs)\n",
    "    \n",
    "    x = mu.ResidualBlock(widths[-1], groups=norm_groups, activation_fn=activation_fn)([x, temb])\n",
    "\n",
    "    # UpBlock\n",
    "    for i in reversed(range(len(widths))):\n",
    "        for _ in range(num_res_blocks + 1):\n",
    "            x = layers.Concatenate(axis=-1)([x, skips.pop()])\n",
    "            x = mu.ResidualBlock(widths[i], groups=norm_groups, activation_fn=activation_fn)([x, temb])\n",
    "            \n",
    "            if has_attention[i]:\n",
    "                x_gfs = gfs_input\n",
    "                for _ in range(i-1):\n",
    "                    x_gfs = layers.Conv2D(widths[i], kernel_size=(2, 2), strides=2, padding=\"same\",)(x_gfs)\n",
    "                x = layers.MultiHeadAttention(num_heads=norm_groups, key_dim=widths[i])(x, x_gfs)\n",
    "\n",
    "        if i != 0:\n",
    "            x = mu.UpSample(widths[i], interpolation=interpolation)(x)\n",
    "\n",
    "    # End block\n",
    "    x = layers.GroupNormalization(groups=norm_groups)(x)\n",
    "    x = activation_fn(x)\n",
    "    x = layers.Conv2D(input_shape[-1], (3, 3), padding=\"same\", kernel_initializer=mu.kernel_init(0.0))(x)\n",
    "    return keras.Model([image_input, time_input, gfs_input], x, name=\"unet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c92957e-dd73-45bb-8fe2-8e03d40691ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse diffusino model\n",
    "model = mu.build_model(input_shape=input_shape, gfs_shape=gfs_shape, widths=widths,\n",
    "                       has_attention=has_attention, num_res_blocks=num_res_blocks, \n",
    "                       norm_groups=norm_groups, activation_fn=keras.activations.swish)\n",
    "\n",
    "# Compile the mdoel\n",
    "model.compile(loss=keras.losses.MeanAbsoluteError(), optimizer=keras.optimizers.Adam(learning_rate=lr),)\n",
    "\n",
    "# load previous weights\n",
    "W_old = mu.dummy_loader(model_name)\n",
    "model.set_weights(W_old)\n",
    "\n",
    "# configure the forward diffusion steps\n",
    "gdf_util = mu.GaussianDiffusion(timesteps=total_timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad250c4-f0c7-433b-b2e0-b66172ce092e",
   "metadata": {},
   "source": [
    "## Validation set preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ab3d4c6-80c1-42df-a6aa-eed53a1d0954",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_valid = 32 # number of validation samples\n",
    "\n",
    "# locations of training data\n",
    "BATCH_dir = '/glade/campaign/cisl/aiml/ksha/BATCH_LDM/'\n",
    "\n",
    "# preparing training batches\n",
    "filenames = np.array(sorted(glob(BATCH_dir+'*.npy')))\n",
    "\n",
    "L = len(filenames)\n",
    "filename_valid = filenames[:][:L_valid]\n",
    "filename_train = list(set(filenames) - set(filename_valid))\n",
    "\n",
    "L_train = len(filename_train)\n",
    "\n",
    "Y_valid = np.empty((L_valid,)+input_shape)\n",
    "X_valid = np.empty((L_valid,)+gfs_shape)\n",
    "\n",
    "for i, name in enumerate(filename_valid):\n",
    "    temp_data = np.load(name, allow_pickle=True)[()]\n",
    "    X_valid[i, ...] = F_x*temp_data['GFS_latent']\n",
    "    Y_valid[i, ...] = F_y*temp_data['Y_latent']\n",
    "\n",
    "# validate on random timesteps\n",
    "t_valid_ = np.random.uniform(low=0, high=total_timesteps, size=(L_valid,))\n",
    "t_valid = t_valid_.astype(int)\n",
    "\n",
    "# sample random noise to be added to the images in the batch\n",
    "noise_valid = np.random.normal(size=((L_valid,)+input_shape))\n",
    "images_valid = np.array(gdf_util.q_sample(Y_valid, t_valid, noise_valid))\n",
    "\n",
    "# validation prediction example:\n",
    "# pred_noise = model.predict([images_valid, t_valid, X_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46046689-c81d-429a-882f-fd6d7c5e11df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "pred_noise = model.predict([images_valid, t_valid, X_valid])\n",
    "record_temp = np.mean(np.abs(noise_valid - pred_noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "679ff81e-ddea-41cf-bfc5-f80442e0470d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6134363051575067"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58b8380-33dc-4ee8-8e37-633a59ca93bc",
   "metadata": {},
   "source": [
    "## Plot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02dbd6b2-7df8-4ce1-b026-a199214d499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2699905-c445-4547-8f4d-5d5718e8f738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_diffuse(model, x_in1, x_in2, total_timesteps, gdf_util):\n",
    "    L_valid = len(x_in1)\n",
    "    x_out = np.empty(x_in1.shape)\n",
    "\n",
    "    for i in range(L_valid):\n",
    "        x1 = x_in1[i, ...][None, ...]\n",
    "        x2 = x_in2[i, ...][None, ...]\n",
    "        \n",
    "        for t in reversed(range(0, total_timesteps)):\n",
    "            tt = tf.cast(tf.fill(1, t), dtype=tf.int64)\n",
    "            pred_noise = model.predict([x1, tt, x2], verbose=0)\n",
    "            model_mean, _, model_log_variance =  gdf_util.p_mean_variance(pred_noise, x=x1, t=tt, clip_denoised=True)\n",
    "            nonzero_mask = (1 - (np.array(tt)==0)).reshape((1, 1, 1, 1))\n",
    "            x1 = np.array(model_mean) + nonzero_mask * np.exp(0.5 * np.array(model_log_variance)) * np.random.normal(size=x1.shape)\n",
    "        x_out[i, ...] = x1\n",
    "\n",
    "    return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4b77071-8d60-434b-a2c5-90e83fca800b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 521.0629842281342 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "Y_pred = reverse_diffuse(model, images_valid, X_valid, total_timesteps, gdf_util)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5901584-a4ea-4342-bf64-614d6ae59a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1188.53125"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "521/32*365*12*6*10/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd34abc3-4361-4136-9d2a-3bd5ad6c97f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a73dd666-069d-4c45-865b-dd6078218ce5",
   "metadata": {},
   "source": [
    "**out-of-box reverse diffusion tests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a70e4b3b-eb7c-487f-ad8d-196335d3a610",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in1 = images_valid\n",
    "x_in2 = X_valid\n",
    "\n",
    "x1 = x_in1[i, ...][None, ...]\n",
    "x2 = x_in2[i, ...][None, ...]\n",
    "\n",
    "t = 99\n",
    "tt = tf.cast(tf.fill(1, t), dtype=tf.int64)\n",
    "pred_noise = model.predict([x1, tt, x2], verbose=0)\n",
    "model_mean, _, model_log_variance =  gdf_util.p_mean_variance(pred_noise, x=x1, t=tt, clip_denoised=True)\n",
    "nonzero_mask = (1 - (np.array(tt)==0)).reshape((1, 1, 1, 1))\n",
    "x1 = np.array(model_mean) + nonzero_mask * np.exp(0.5 * np.array(model_log_variance)) * np.random.normal(size=x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060b4612-b21f-4728-97e6-4cfb7dd871da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "103eb489-8a3c-431c-bca9-2dc2f6ba585c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in1 = images_valid\n",
    "x_in2 = X_valid\n",
    "\n",
    "x1 = x_in1[i, ...][None, ...]\n",
    "x2 = x_in2[i, ...][None, ...]\n",
    "\n",
    "for t in reversed(range(0, total_timesteps)):\n",
    "    tt = tf.cast(tf.fill(1, t), dtype=tf.int64)\n",
    "    pred_noise = model.predict([x1, tt, x2], verbose=0)\n",
    "    model_mean, _, model_log_variance =  gdf_util.p_mean_variance(pred_noise, x=x1, t=tt, clip_denoised=True)\n",
    "    nonzero_mask = (1 - (np.array(tt)==0)).reshape((1, 1, 1, 1))\n",
    "    x1 = np.array(model_mean) + nonzero_mask * np.exp(0.5 * np.array(model_log_variance)) * np.random.normal(size=x1.shape)\n",
    "\n",
    "    if np.sum(np.isnan(x1)) > 0:\n",
    "        print(t)\n",
    "        aergaegr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a720ba7f-296e-4772-ba6a-69190cacae44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
